{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08a71fb-12a1-4b20-9d04-b0896d3f33ae",
   "metadata": {},
   "source": [
    "# The Unappealingly Titled Project H2O\n",
    "\n",
    "- Python version (see folder for R code)\n",
    "- work in progress\n",
    "\n",
    "## Objective\n",
    "\n",
    "We are primarily interested in participats' ability to discriminate between tap and potted water of some brand on average. In the second place, we are interested in assessing individual's ability to identify the sampled water conditional on their confidence.\n",
    "\n",
    "## Methods\n",
    "\n",
    "The sampling process will span up to two months owing to constraints. The aim is to collect the largest sample attainable in up to five rounds per participant. See Sample collection below.\n",
    "\n",
    "The analysis will consist of three parts. We shall assess (i) the collective ability in each round using the A/B test and the exact Fisher test, (ii) the collective ability across rounds using generalised estimating equations, and (iii) the individual ability across rounds using the Brier score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f77f1-a0a5-48f4-bef7-329ac462193e",
   "metadata": {},
   "source": [
    "### Frequentist estimates\n",
    "\n",
    "The frequentist estimates are simple proportions of counts $n_{k1}$ in the marginal group counts $n_k$.\n",
    "\n",
    "|           | success (guessed potted water) $(g = 1)$ | failure (guessed tap water) $(g = 2)$ | sample margin |\n",
    "| --------- | ------- | ------- | ----- |\n",
    "| **treatment (sampled potted water)** $(s = 1)$ | $n_{11}$     | $n_{12}$     | $n_{s_p}=n_{11}+n_{12}$ |\n",
    "| **control (sampled tap water)** $(s = 2)$ | $n_{21}$     | $n_{22}$     | $n_{s_t}=n_{21}+n_{22}$ |\n",
    "| **guess margin** | $n_{g_p}=n_{11}+n_{21}$   | $n_{g_t}=n_{12}+n_{22}$   | $N=n_{11}+n_{12}+n_{21}+n_{22}$   |\n",
    "\n",
    "Then, estimators $\\hat{p}_1 = \\frac{1}{n_{s_p}} \\sum_{i=1}^{n_{s_p}} 1_{\\{g_i = 1\\}} = \\frac{n_{11}}{n_{s_p}}$ and $\\hat{p}_2 = \\frac{1}{n_{s_t}} \\sum_{i=1}^{n_{s_t}} 1_{\\{g_i = 1\\}} = \\frac{n_{21}}{n_{s_t}}$ solve the Bernoulli likelihood $\\mathcal{L}(p_k;y_k)=\\prod_{i=1}^{n_k}p_k^{y_{ki}}(1-p_k)^{1-y_{ki}}=p_k^{n_{k1}}(1-p_k)^{n_k-n_{k1}}$ where $n_{k1}$ is the count of successes in $n_{k}$ trials in sample group $k \\in \\{1,2\\}=\\{s_p,s_t\\}$ and individual outcomes $y_{ki}\\in \\{0,1\\}=\\{t,p\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158cb2a-963d-437e-832f-bc4d15c15b57",
   "metadata": {},
   "source": [
    "#### Risk and odds ratios\n",
    "\n",
    "| measure | estimator | null |\n",
    "|---------|-----------|------|\n",
    "| risk ratio | $\\rho=\\frac{p_1}{p_2}$ | $H_0:\\rho=\\rho_0=1$ |\n",
    "| odds ratio | $\\theta=\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}$ | $H_0:\\theta=\\theta_0=1$ |\n",
    "\n",
    "##### Risk ratio confidence intervals\n",
    "\n",
    "$$\n",
    "\\hat \\rho = \\frac{\\hat p_1}{\\hat p_2}, \\qquad\n",
    "\\log \\hat \\rho = \\log(\\hat p_1) - \\log(\\hat p_2).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widehat{\\text{SE}}(\\log \\hat \\rho)\n",
    "= \\sqrt{\\frac{1 - \\hat p_1}{\\hat p_1 n_{s_p}} + \\frac{1 - \\hat p_2}{\\hat p_2 n_{s_t}}}=\\sqrt{\\frac{1}{n_{11}} - \\frac{1}{n_{11}+n_{12}} + \\frac{1}{n_{21}} - \\frac{1}{n_{21}+n_{22}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\rho \\in \\exp{\\left( \\ln{\\hat{\\rho}}\\pm Z_{1-\\alpha/2}\\sqrt{\\widehat{\\text{SE}}(\\ln{\\hat{\\rho}})} \\right)}\n",
    "$$\n",
    "\n",
    "##### Odds ratio confidende intervals\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{n_{11} n_{22}}{n_{21} n_{12}}, \\quad\n",
    "\\log \\hat \\theta = \\log n_{11} + \\log n_{22} - \\log n_{12} - \\log n_{21},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widehat{\\text{SE}}(\\ln{\\hat{\\theta}})\n",
    "= \\sqrt{\\frac{1}{n_{11}}+\\frac{1}{n_{12}}+\\frac{1}{n_{21}}+\\frac{1}{n_{22}}}.\n",
    "$$\n",
    "\n",
    "Note that we commonly add $0.5$ to each $n_{kj}$ to avoid division by zero.\n",
    "\n",
    "$$\n",
    "\\theta \\in \\exp{\\left( \\ln{ \\hat \\theta \\pm Z_{1-\\alpha/2}\\ \\widehat{\\mathrm{SE}}(\\ln{\\hat{\\theta}}) } \\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fe6b1-5da1-494e-bf72-dc7851eaa4bb",
   "metadata": {},
   "source": [
    "### Bayesian estimates\n",
    "\n",
    "We shall use a standard beta-binomial setup with conjugate priors. This is generally summarised with the continuous form of the Bayes rule like so,\n",
    "\n",
    "$$\n",
    "f(\\theta \\mid y) = \\frac{\\prod_{i=1}^{n_k} g(y \\mid \\theta) f(\\theta)}{\\int g(y \\mid \\theta) f(\\theta) \\, d\\theta}\n",
    "$$\n",
    "\n",
    "We set up the model like so, \n",
    "\n",
    "- $y_k \\mid p_k \\sim \\text{binomial}(n_k, p_k), \\text{for } k=1,2$ (likelihood)\n",
    "- $p_k \\sim \\text{Beta}(\\alpha, \\beta)$, choose non-informative $p_k \\sim \\text{Beta}(\\frac{1}{2}, \\frac{1}{2})$ (Jeffreys prior) \n",
    "- $p_k \\mid y_k \\sim \\text{Beta}(y_k+\\alpha,n_k-y_k+\\beta) = \\text{Beta}(\\frac{1}{2}+y_k,\\frac{1}{2}+n_k-y_k)$ (implied posterior)\n",
    "\n",
    "Hence the posterior,\n",
    "\n",
    "$$\n",
    "f(p_k \\mid y_k) \\propto \\mathcal{L}(p_k;y_k) f(p_k) = \\left(p_k^{y_k}(1-p_k)^{n_k-y_k}\\right)\\left(p_k^{\\frac{1}{2}-1}(1-p_k)^{\\frac{1}{2}-1}\\right) = p_k^{y_k-\\frac{1}{2}}(1-p_k)^{n_k-y_k-\\frac{1}{2}}\n",
    "$$\n",
    "\n",
    "We shall run 16e4 simulations with an additional 4e4 burnin in six chains, and we are interested in the median and the 95% credible interval. We use the estimates to compute the risk and odds ratios and the respective credible intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc01e43-f86f-48c9-95c0-504e04df8eea",
   "metadata": {},
   "source": [
    "### Generalised estimating equations\n",
    "\n",
    "Generalised estimating equations approximate the (marginal) population-average effect for our clustered sample of $i=1,...,M$ individuals across $j=1,...,5$ rounds. GEE apply robust standard errors to allow valid inference.\n",
    "\n",
    "The results are interpreted as a binomial logit model like so,\n",
    "\n",
    "$$\n",
    "\\text{logit}\\left(\\pi_{ij}\\right)=\\ln{\\left(\\frac{\\pi_{ij}}{1-\\pi_{ij}}\\right)}=\\beta_0+\\beta_1 x_{ij}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "- $\\pi_{ij}=P(Y_{ij}=1)=\\mathbb{E}\\left[Y_{ij} \\mid X_{ij} \\right]=\\text{logit}^{-1}(X_{ij}'\\beta)$ is the probability that participant $i$ gets predicts potted water ($g=1$) in round $j$\n",
    "- $\\frac{\\pi_{ij}}{1-\\pi_{ij}}$ is the odds of predicting potted water ($g=1$)\n",
    "- $\\beta_0$ is the log-odds when $x_{ij} = 0$ (intercept)\n",
    "- $\\beta_1$ is the effect of $x_{ij} = 1$ on the log-odds\n",
    "\n",
    "GEE solve the following gradient for $\\beta$,\n",
    "\n",
    "$$\n",
    "U(\\beta)=\\sum_{i=1}^N D_i'V_i^{-1}(y_i-\\mu_i)=0\n",
    "$$\n",
    "\n",
    "Where $D_i=\\frac{\\partial \\pi_i}{\\partial \\beta'}=A_i X_i$ with $A_i = \\text{diag}\\left(v(\\mu_{it})\\right)$ and the working covariance,\n",
    "\n",
    "$$\n",
    "V_i = \\phi A_i^{1/2},R(\\alpha),A_i^{1/2},\\quad\n",
    "A_i=\\text{diag}\\,\\left(\\pi_{ij}(1-\\pi_{ij})\\right)\n",
    "$$\n",
    "\n",
    "Where $R(\\alpha_i)=\\left[\\begin{matrix} 1 & \\alpha & \\alpha & \\dots & \\alpha \\\\ \\alpha & 1 & \\alpha & \\dots & \\alpha \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ \\alpha & \\alpha & \\dots & 1\\end{matrix}\\right]$ is the exchangeable working correlation structure. No closed form exists. The algorithm solves the system iteratively.\n",
    "\n",
    "#### Retrieve probabilities\n",
    "\n",
    "$$\n",
    "\\pi_0=\\text{logit}^{-1}(\\beta_0)=\\frac{1}{1+e^{-\\beta_0}}=1-\\frac{1}{1+e^{\\beta_0}}=\\text{plogis}(\\beta_0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi_1=\\text{logit}^{-1}(\\beta_0 + \\beta_1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1)}}=1-\\frac{1}{1+e^{\\beta_0+\\beta_1}}=\\text{plogis}(\\beta_0 + \\beta_1)\n",
    "$$\n",
    "\n",
    "#### Relative risk\n",
    "\n",
    "$$\n",
    "\\hat{\\rho}=\\frac{\\hat{\\pi}_1}{\\hat{\\pi}_0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln{(\\hat{\\rho})}=\\ln{\\left(\\frac{\\pi_1(\\beta)}{\\pi_0(\\beta)}\\right)}=\\ln{\\left(\\frac{\\text{logit}^{-1}(\\beta_0+\\beta_1)}{\\text{logit}^{-1}(\\beta_0)}\\right)}\n",
    "$$\n",
    "\n",
    "With confidence intervals,\n",
    "\n",
    "$$\n",
    "\\rho \\in \\exp{\\left(\\ln{\\hat{\\rho}}\\pm Z_{1-\\alpha/2}\\,\\widehat{\\text{SE}}(\\ln{\\hat{\\rho}})\\right)}, \\quad\n",
    "\\text{Var}\\left(\\ln{\\hat{\\rho}}\\right)\\approx g'\\widehat{\\text{Var}}_{\\text{gp}}(\\hat{\\beta})g, \\quad\n",
    "g=\\left[\\begin{matrix}\\frac{\\partial\\ln{\\hat{\\rho}}}{\\partial\\beta_0} \\\\ \\frac{\\partial\\ln{\\hat{\\rho}}}{\\partial\\beta_1}\\end{matrix}\\right]=\\left[\\begin{matrix}\\hat{\\pi}_0-\\hat{\\pi}_1 \\\\ 1-\\hat{\\pi}_1\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "#### Odds ratio\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}=\\frac{\\hat{\\pi}_1/1-\\hat{\\pi}_1}{\\hat{\\pi}_0/1-\\hat{\\pi}_0}\n",
    "$$\n",
    "\n",
    "With confidence intervals,\n",
    "\n",
    "$$\n",
    "\\theta \\in \\exp{\\left(\\ln{\\hat{\\theta}}\\pm Z_{1-\\alpha/2}\\,\\text{SE}(\\ln{\\hat{\\beta}})\\right)}, \\quad \\text{SE}(\\ln{\\hat{\\beta}})=\\text{SE}(\\ln{\\hat{\\theta}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e4657-46b4-43ac-937f-93dee3bc2c21",
   "metadata": {},
   "source": [
    "### Brier score\n",
    "\n",
    "The typical Brier score for a set of clustered outcomes and predictions for $j=1,...,J$ measures the accuracy of the participant's predictions as follows,\n",
    "\n",
    "$$\n",
    "\\text{BS}=\\frac{1}{n}\\sum_{j=1}^J (P_j - 1_{\\{X_j = 1\\}})^2\n",
    "$$\n",
    "\n",
    "Where $P_j \\in [0,1]$ is a measure of the participant's confidence in the outcome $X_j \\in \\{0,1\\}$. Particularly $P_j \\to 1$ implies higher confidence in $X_j = 1$ and $P_j \\to 0$ implies a lower confidence in $X_j = 1$. Lower $BS$ imply a higher accuracy. See Brier (1950).\n",
    "\n",
    "This can be reconceived as a measure of confidence like so,\n",
    "\n",
    "$$\n",
    "\\text{BS}=\\frac{1}{n}\\sum_{j=1}^J (Z_j - 1_{\\{S_j = 1\\}})^2, \\quad\n",
    "S_j =\n",
    "\\begin{cases}\n",
    "1, & X_j = Y_j,\\\\\n",
    "0, & X_j \\neq Y_j\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $X_j \\in {\\{0,1\\}}$ denotes the outcome, $Y_j \\in {\\{0,1\\}}$ denotes the categorical prediction, $S_j \\in {\\{0,1\\}}$ is the correctnes indicator and $Z_j \\in [0,1]$ is the confidence level indicator. The participant then predicts the outcome $Z_j$ with a level of confidence $Z_j$ on a continuous scale from 0% (not at all confident) to 100% (absolutely certain). Once more a lower $BS$ implies a higher accuracy. See Juslin (1994) for a similar setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdff25-fa82-4124-bbe5-6d6189c0b092",
   "metadata": {},
   "source": [
    "## Sample collection\n",
    "\n",
    "The samples will be collected in $k=1,...,5$ rounds per each individual $i$ in $n$ participants. In each round $k$, each participant $i$ will be randomly assigned to group $T$ (tap water) or $P$ (potted water). This assignment will be carried out by a draw from the Bernoulli distribution with $p=\\frac{1}{2}$. An ordered set of 100 values $0$ ($T$) and $1$ ($P$) will be generated every Monday and each participant will be allotted $0$ or $1$ on a first come first serve basis.\n",
    "\n",
    "Each round will use a different brand of potted water - Evian, Volvic, Highland Spring, Buxton, Waitrose Essentials - and unfiltered tap water drawn from the same tap. Both will be cooled to the like temperature overnight at most. Samples will be poured from reusable vessels and tasted from disposable cups.\n",
    "\n",
    "For each participant, we record (I) an identifier (first name), (II) the water sample tasted ($0$ or $1$), (III) the guess ($T$ or $P$), and (IV) level of confidence ([$0,100%$] from not at all confident to absolutely certain).\n",
    "\n",
    "The participant with the most accurate score across all five rounds wins six bottles of the potted water that has done best against the tap water. In case of more than one winner, a draw from the uniform distribution decides.\n",
    "\n",
    "The sample collection is expected to conclude by the end of November 2025. The results ought to follow by mid-December.\n",
    "\n",
    "Caveats: Logistic difficulties preclude the application of a double blind test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f445f98-c639-45b4-a2bd-e5b419de841e",
   "metadata": {},
   "source": [
    "## Reference material\n",
    "\n",
    "Agresti, A. (2019) *An Introduction to Categorical Data Analysis*, 3rd edn. Wiley.\n",
    "\n",
    "Agresti, A. (2002) *Categorical Data Analysis*, 2nd edn. Wiley.\n",
    "\n",
    "Brier, G.W. (1950) 'Verification of Forecasts Expressed in Terms of Probability'. *Monthly Weather Review*, Volume 78, Number 1. https://web.archive.org/web/20171023012737/https://docs.lib.noaa.gov/rescue/mwr/078/mwr-078-01-0001.pdf\n",
    "\n",
    "Ford, C. (2023) 'Getting Started with Generalized Estimating Equations'. University of Virginia Library. https://library.virginia.edu/data/articles/getting-started-with-generalized-estimating-equations\n",
    "\n",
    "Goldstein-Greenwood, J. (2021) 'A Brief on Brier Scores'. University of Virginia Library. https://library.virginia.edu/data/articles/a-brief-on-brier-scores\n",
    "\n",
    "Hardin, J.W. and Hilbe, J.M. (2013) *Generalised Estimating Equations*, 2nd edn. CRC Press.\n",
    "\n",
    "Hoessly, L. (2025) 'On misconceptions about the Brier score in binary prediction models'. arXiv. https://arxiv.org/html/2504.04906v3\n",
    "\n",
    "Hoff, P.D. (2009) *A First Course in Bayesian Statistical Methods*. Springer.\n",
    "\n",
    "Juslin, P. (1994) 'The Overconfidence Phenomenon as a Consequence of Informal Experimenter-Guided Selection of Almanac Items'. *Organizational Behavior and Human Decision Processes* 57, 226-246.\n",
    "\n",
    "Marin, J.M. and Robert, C. (2014) *Bayesian Essentials with R*, 2nd edn. Springer.\n",
    "\n",
    "Matsuura, K. (2022) *Bayesian Statistical Modeling with Stan, R, and Python*. Springer.\n",
    "\n",
    "Robert, D. (2020) 'Five Confidence Intervals for Proportions That You Should Know About'. Towards Data Science. https://towardsdatascience.com/five-confidence-intervals-for-proportions-that-you-should-know-about-7ff5484c024f/\n",
    "\n",
    "Stan Development Team (2024) 'Documentation'. https://mc-stan.org/docs/\n",
    "\n",
    "StatsModels (2023) 'Generalized Estimating Equations'. https://www.statsmodels.org/stable/gee.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc91d8-5b19-46a4-9950-17ed5fcae5b8",
   "metadata": {},
   "source": [
    "## Machinery check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b280cb-c4da-4875-b362-b07156e3c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import norm\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352209b-ec51-4e6b-a451-6639efed9a03",
   "metadata": {},
   "source": [
    "### Data structure and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90f7962-a631-47e6-95c1-7c83f633f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participant_id', 'round0_sample', 'round0_prediction',\n",
      "       'round0_confidence', 'round1_sample', 'round1_prediction',\n",
      "       'round1_confidence', 'round2_sample', 'round2_prediction',\n",
      "       'round2_confidence', 'round3_sample', 'round3_prediction',\n",
      "       'round3_confidence', 'round4_sample', 'round4_prediction',\n",
      "       'round4_confidence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Construct a data frame\n",
    "df_dict = {\n",
    "    \"participant_id\": []\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "    col1 = f\"round{i}_sample\"\n",
    "    col2 = f\"round{i}_prediction\"\n",
    "    col3 = f\"round{i}_confidence\"\n",
    "    \n",
    "    df_dict[col1] = []\n",
    "    df_dict[col2] = []\n",
    "    df_dict[col3] = []\n",
    "\n",
    "df = pd.DataFrame(df_dict)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50577a31-f86a-495c-8f9d-af11d81cb13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>round0_sample</th>\n",
       "      <th>round0_prediction</th>\n",
       "      <th>round0_confidence</th>\n",
       "      <th>round1_sample</th>\n",
       "      <th>round1_prediction</th>\n",
       "      <th>round1_confidence</th>\n",
       "      <th>round2_sample</th>\n",
       "      <th>round2_prediction</th>\n",
       "      <th>round2_confidence</th>\n",
       "      <th>round3_sample</th>\n",
       "      <th>round3_prediction</th>\n",
       "      <th>round3_confidence</th>\n",
       "      <th>round4_sample</th>\n",
       "      <th>round4_prediction</th>\n",
       "      <th>round4_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hazel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beatrice</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Louis</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Francesca</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jemma</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rachael</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jill</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jamie</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Audrey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  round0_sample  round0_prediction  round0_confidence  \\\n",
       "0          Wayne              1                  1               0.72   \n",
       "1          Hazel              0                  0               0.91   \n",
       "2       Beatrice              1                  0               0.40   \n",
       "3         Louis               1                  0               0.27   \n",
       "4      Francesca              0                  1               0.83   \n",
       "5          Jemma              0                  1               0.63   \n",
       "6        Rachael              1                  1               0.50   \n",
       "7           Jill              1                  1               0.82   \n",
       "8         Jamie               1                  0               0.58   \n",
       "9         Audrey              0                  1               0.18   \n",
       "\n",
       "   round1_sample  round1_prediction  round1_confidence  round2_sample  \\\n",
       "0              0                  0               0.75              1   \n",
       "1              0                  0               0.70              0   \n",
       "2              0                  1               0.29              0   \n",
       "3              1                  1               0.75              0   \n",
       "4              0                  0               0.28              1   \n",
       "5              1                  0               0.00              1   \n",
       "6              1                  0               0.09              1   \n",
       "7              1                  0               0.90              1   \n",
       "8              1                  0               0.80              1   \n",
       "9              0                  1               0.07              0   \n",
       "\n",
       "   round2_prediction  round2_confidence  round3_sample  round3_prediction  \\\n",
       "0                  0               0.65              1                  1   \n",
       "1                  0               0.10              0                  0   \n",
       "2                  0               0.23              1                  1   \n",
       "3                  1               0.08              1                  0   \n",
       "4                  1               0.76              1                  1   \n",
       "5                  1               0.08              0                  1   \n",
       "6                  0               0.86              0                  1   \n",
       "7                  1               0.30              1                  0   \n",
       "8                  0               0.51              0                  0   \n",
       "9                  0               0.15              0                  1   \n",
       "\n",
       "   round3_confidence  round4_sample  round4_prediction  round4_confidence  \n",
       "0               0.46              0                  1               0.38  \n",
       "1               0.05              1                  1               0.36  \n",
       "2               0.45              0                  0               0.26  \n",
       "3               0.26              1                  1               0.55  \n",
       "4               0.87              0                  0               1.00  \n",
       "5               0.31              0                  1               0.74  \n",
       "6               0.85              1                  0               0.77  \n",
       "7               0.13              1                  1               0.83  \n",
       "8               0.45              1                  0               0.41  \n",
       "9               0.99              0                  0               0.59  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate mock data\n",
    "    # Load up some names\n",
    "# url = r\"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/datasets/babynamesenglandandwalestop100babynameshistoricaldata/1904to2024/historicalnames2024.xlsx\"\n",
    "url = r\"D:\\data\\ons_names\\historicalnames2024.xlsx\"\n",
    "\n",
    "data_g = pd.read_excel(url, sheet_name = \"Table_1\", skiprows = 3)\n",
    "data_b = pd.read_excel(url, sheet_name = \"Table_2\", skiprows = 3)\n",
    "\n",
    "data_g = data_g.drop(\"Rank\", axis=1)\n",
    "data_g = pd.melt(data_g, value_vars=data_g.columns, value_name=\"name\")[\"name\"]\n",
    "\n",
    "data_b = data_b.drop(\"Rank\", axis=1)\n",
    "data_b = pd.melt(data_b, value_vars=data_b.columns, value_name=\"name\")[\"name\"]\n",
    "\n",
    "names_df = pd.concat([data_g, data_b], ignore_index=True)\n",
    "names_df = names_df.dropna()\n",
    "names_df = names_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "    # Construct a mock df\n",
    "df_cols = df.columns\n",
    "no_observations = 30\n",
    "\n",
    "mock_df = pd.DataFrame({\n",
    "    df_cols[0]: random.sample(names_df.tolist(), k=no_observations)\n",
    "})\n",
    "\n",
    "for i in range(1, len(df_cols), 3):\n",
    "    col1 = [random.randint(0,1) for i in range(no_observations)]\n",
    "    col2 = [random.randint(0,1) for i in range(no_observations)]\n",
    "    col3 = [random.randint(0,100) / 100 for i in range(no_observations)]\n",
    "\n",
    "    mock_df[df_cols[i]] = col1\n",
    "    mock_df[df_cols[i + 1]] = col2\n",
    "    mock_df[df_cols[i + 2]] = col3\n",
    "\n",
    "mock_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af53c5c4-4b5a-4e82-bb15-abfb3e7a0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug in the data\n",
    "data_df = mock_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc3337-02e7-4a8b-9b82-6501021f6839",
   "metadata": {},
   "source": [
    "#### Contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdadf51-f96b-4867-98a2-48541ffdb068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          guess_t  guess_p\n",
      "sample_0        6        9\n",
      "sample_1        9        6\n",
      "          guess_t  guess_p\n",
      "sample_0        8        7\n",
      "sample_1       10        5\n",
      "          guess_t  guess_p\n",
      "sample_0        9        8\n",
      "sample_1        7        6\n",
      "          guess_t  guess_p\n",
      "sample_0        8        8\n",
      "sample_1        8        6\n",
      "          guess_t  guess_p\n",
      "sample_0        6        8\n",
      "sample_1        5       11\n"
     ]
    }
   ],
   "source": [
    "# Round dfs\n",
    "df_dict = {}\n",
    "df_counter = 0\n",
    "\n",
    "for i in range(1, len(df_cols), 3):\n",
    "    df_counter += 1\n",
    "\n",
    "    samp = df_cols[i]\n",
    "    pred = df_cols[i + 1]\n",
    "    df_name = f\"round{df_counter}\"\n",
    "\n",
    "    df_dict[df_name] = pd.DataFrame({\n",
    "        \"guess_t\": [\n",
    "            # True negatives\n",
    "            sum((data_df[samp] == 0) & (data_df[pred] == 0)),\n",
    "            # False negatives\n",
    "            sum((data_df[samp] == 1) & (data_df[pred] == 0))\n",
    "        ],\n",
    "        \"guess_p\": [\n",
    "            # False positives\n",
    "            sum((data_df[samp] == 0) & (data_df[pred] == 1)),\n",
    "            # True positives\n",
    "            sum((data_df[samp] == 1) & (data_df[pred] == 1))\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    df_dict[df_name].index = [\"sample_0\", \"sample_1\"]\n",
    "\n",
    "    print(df_dict[df_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12810c99-689f-4733-bb53-4edd6e9b91dc",
   "metadata": {},
   "source": [
    "### Frequentist estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438317c5-a3dc-44e3-8dba-19215b3b4f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>relative_risk</th>\n",
       "      <th>rr_ci_lower</th>\n",
       "      <th>rr_ci_upper</th>\n",
       "      <th>rr_significance</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>or_ci_lower</th>\n",
       "      <th>or_ci_upper</th>\n",
       "      <th>or_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>round1</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>1.4042</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>1.9154</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round2</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>1.4481</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>2.5026</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round3</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.5011</td>\n",
       "      <td>1.9289</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>4.1017</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>round4</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>1.7061</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>3.1734</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>round5</td>\n",
       "      <td>1.3714</td>\n",
       "      <td>0.5328</td>\n",
       "      <td>3.5304</td>\n",
       "      <td>None</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>7.3651</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round  relative_risk  rr_ci_lower  rr_ci_upper rr_significance  \\\n",
       "0  round1         0.6667       0.3165       1.4042            None   \n",
       "1  round2         0.8000       0.4420       1.4481            None   \n",
       "2  round3         0.9832       0.5011       1.9289            None   \n",
       "3  round4         0.8750       0.4488       1.7061            None   \n",
       "4  round5         1.3714       0.5328       3.5304            None   \n",
       "\n",
       "   odds_ratio  or_ci_lower  or_ci_upper or_significance  \n",
       "0      0.4444       0.1031       1.9154            None  \n",
       "1      0.5714       0.1305       2.5026            None  \n",
       "2      0.9643       0.2267       4.1017            None  \n",
       "3      0.7500       0.1773       3.1734            None  \n",
       "4      1.6500       0.3696       7.3651            None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relative risk and odds ratio\n",
    "\n",
    "    # Two-tailed z-score\n",
    "p = 0.05\n",
    "z = norm.ppf(1 - p / 2)\n",
    "\n",
    "significance_levels = {\n",
    "    \"10pc\": \"*\",\n",
    "    \"5pc\": \"**\",\n",
    "    \"1pc\": \"***\"\n",
    "}\n",
    "\n",
    "\n",
    "    # Construct a data frame\n",
    "ab_results_dict = {\n",
    "    \"round\": [],\n",
    "    \"relative_risk\": [],\n",
    "    \"rr_ci_lower\": [],\n",
    "    \"rr_ci_upper\": [],\n",
    "    \"rr_significance\": [],\n",
    "    \"odds_ratio\": [],\n",
    "    \"or_ci_lower\": [],\n",
    "    \"or_ci_upper\": [],\n",
    "    \"or_significance\": []\n",
    "}\n",
    "\n",
    "ab_results = pd.DataFrame(ab_results_dict)\n",
    "\n",
    "    # Compute the stats\n",
    "for i in range(len(df_dict)):\n",
    "    df_name = list(df_dict.keys())[i]\n",
    "    df_i = list(df_dict.values())[i]\n",
    "\n",
    "    # Relative risk\n",
    "    rho = (df_i.iat[0,0] / df_i.iloc[0,].sum()) / (df_i.iat[1,0] / df_i.iloc[1,].sum())\n",
    "    rr = round(rho, 4)\n",
    "    # RR confidence interval\n",
    "    rr_se = math.sqrt((1 / df_i.iat[0,0]) - (1 / df_i.iloc[0,].sum()) + (1 / df_i.iat[1,0]) - (1 / df_i.iloc[1,].sum()))\n",
    "    rr_ci = [\n",
    "        round(math.exp(math.log(rho) - z * rr_se), 4),\n",
    "        round(math.exp(math.log(rho) + z * rr_se), 4)\n",
    "    ]\n",
    "    # RR significance\n",
    "    rr_significance = significance_levels[f\"{int(p * 100)}pc\"] if (rr_ci[0] > 1) or (rr_ci[1] < 1) else None\n",
    "\n",
    "    # Odds ratio\n",
    "    theta = (df_i.iat[0,0] / df_i.iat[0,1]) / (df_i.iat[1,0] / df_i.iat[1,1])\n",
    "    or_i = round(theta, 4) \n",
    "    # OR confidence interval\n",
    "    or_se = math.sqrt(sum([(1 / x) for x in df_i.to_numpy().flatten()]))\n",
    "    or_ci = [\n",
    "        round(math.exp(math.log(theta) - z * or_se), 4),\n",
    "        round(math.exp(math.log(theta) + z * or_se), 4)\n",
    "    ]\n",
    "    # OR significance\n",
    "    or_significance = significance_levels[f\"{int(p * 100)}pc\"] if (or_ci[0] > 1) or (or_ci[1] < 1) else None \n",
    "    \n",
    "    # Add the row to the df\n",
    "    ab_results.loc[i] = {\n",
    "        \"round\": df_name, \n",
    "        \"relative_risk\": rr, \n",
    "        \"rr_ci_lower\": rr_ci[0], \n",
    "        \"rr_ci_upper\": rr_ci[1], \n",
    "        \"rr_significance\": rr_significance, \n",
    "        \"odds_ratio\": or_i, \n",
    "        \"or_ci_lower\": or_ci[0], \n",
    "        \"or_ci_upper\": or_ci[1], \n",
    "        \"or_significance\": or_significance\n",
    "    }\n",
    "\n",
    "ab_results.head(n=len(ab_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38d55a-ebb5-4c61-98e7-f608f80bf59e",
   "metadata": {},
   "source": [
    "Discussion here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba5ddd-cfa7-401d-8a08-5467c11114a8",
   "metadata": {},
   "source": [
    "### Estimating equations model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f247ee-49a6-444c-808f-6ff3142fb4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>round</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>round0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>round1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>round2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>round3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>round4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id   round  prediction  sample\n",
       "0          Wayne  round0           1       1\n",
       "1          Wayne  round1           0       0\n",
       "2          Wayne  round2           0       1\n",
       "3          Wayne  round3           1       1\n",
       "4          Wayne  round4           1       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating equations\n",
    "\n",
    "gee_df = data_df.loc[:, ~data_df.columns.str.contains(\"confidence\")]\n",
    "gee_df = gee_df.rename(columns=lambda c: re.sub(r\"^(round\\d+)_(prediction|sample)$\", r\"\\2_\\1\", c)) # Flip the col name pattern for pd.wide_to_long\n",
    "gee_df = gee_df.reset_index(names=\"row_id\") # pd.wide_to_long expects a constructible unique identifier\n",
    "\n",
    "gee_df = pd.wide_to_long(\n",
    "    gee_df,\n",
    "    stubnames=[\"prediction\", \"sample\"],\n",
    "    i=[\"participant_id\", \"row_id\"],\n",
    "    j=\"round\",\n",
    "    sep=\"_\",\n",
    "    suffix=r\"round\\d+\"\n",
    ").reset_index().drop(columns=\"row_id\") \n",
    "\n",
    "gee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cdfbb8-c7ae-4e03-961b-2480c781e3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>round</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Elliott</td>\n",
       "      <td>round0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Elliott</td>\n",
       "      <td>round1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Elliott</td>\n",
       "      <td>round2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Elliott</td>\n",
       "      <td>round3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Elliott</td>\n",
       "      <td>round4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant_id   round  prediction  sample\n",
       "145        Elliott  round0           0       0\n",
       "146        Elliott  round1           0       1\n",
       "147        Elliott  round2           0       0\n",
       "148        Elliott  round3           1       1\n",
       "149        Elliott  round4           0       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gee_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d76d31bc-98cb-48a2-b172-7611584a84dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               GEE Regression Results                              \n",
      "===================================================================================\n",
      "Dep. Variable:                  prediction   No. Observations:                  150\n",
      "Model:                                 GEE   No. clusters:                       30\n",
      "Method:                        Generalized   Min. cluster size:                   5\n",
      "                      Estimating Equations   Max. cluster size:                   5\n",
      "Family:                           Binomial   Mean cluster size:                 5.0\n",
      "Dependence structure:         Exchangeable   Num. iterations:                     5\n",
      "Date:                     Sat, 08 Nov 2025   Scale:                           1.000\n",
      "Covariance type:                    robust   Time:                         09:52:44\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0909      0.219      0.415      0.678      -0.338       0.520\n",
      "sample        -0.2418      0.340     -0.711      0.477      -0.908       0.424\n",
      "==============================================================================\n",
      "Skew:                          0.0265   Kurtosis:                      -1.9847\n",
      "Centered skew:                -0.0569   Centered kurtosis:             -1.3756\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mod = smf.gee(\n",
    "    \"prediction ~ sample\", \n",
    "    \"participant_id\", \n",
    "    gee_df, \n",
    "    cov_struct=sm.cov_struct.Exchangeable(), \n",
    "    family=sm.families.Binomial()\n",
    ")\n",
    "\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e4d540-dce5-4c2d-85fd-2ffb09ec3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimates\n",
    "gee_estimates = res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cced1f0-c480-4171-932e-8ca233c4e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline probability (s = 0)\n",
    "beta_0 = gee_estimates.iloc[0]\n",
    "pi_0 = 1 / (1 + math.exp(-beta_0)) # Or res.model.family.link.inverse(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ffc3812-0649-4f43-98a5-f9b221613ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability (s = 1)\n",
    "beta_1 = gee_estimates.iloc[1]\n",
    "pi_1 = 1 / (1 + math.exp(-(beta_0 + beta_1))) # Or res.model.family.link.inverse(beta_0 + beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee07414c-5c9a-4452-9702-0f7444b375de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population averaged risk ratio\n",
    "rr_hat = pi_1 / pi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223756a2-80bc-463b-8548-e359ad2dfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RR CIs\n",
    "V = res.cov_params().loc[[\"Intercept\",\"sample\"], [\"Intercept\",\"sample\"]].to_numpy()\n",
    "g = np.array([pi_0 - pi_1, 1 - pi_1])\n",
    "gee_rr_var = g @ V @ g\n",
    "gee_rr_ses = np.sqrt(gee_rr_var)\n",
    "\n",
    "gee_rr_cis = (\n",
    "    math.exp(math.log(rr_hat) - (z * gee_rr_ses)),\n",
    "    math.exp(math.log(rr_hat) + (z * gee_rr_ses))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af552d0b-d68e-4330-8b1e-48eb12dc4f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Population averaged odds ratio\n",
    "or_hat = math.exp(beta_1)\n",
    "np.isclose(or_hat, (pi_1/(1 - pi_1)) / (pi_0/(1 - pi_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae4fdb11-0735-4ced-8f2a-63685f9c840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR CIs\n",
    "gee_or_se = np.sqrt(res.cov_params().loc[\"sample\", \"sample\"])\n",
    "\n",
    "gee_or_cis = (\n",
    "    math.exp(math.log(or_hat) - (z * gee_or_se)),\n",
    "    math.exp(math.log(or_hat) + (z * gee_or_se))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10818c53-2771-45ab-af04-da2c2f103a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_0</th>\n",
       "      <th>pi_0</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>pi_1</th>\n",
       "      <th>risk_ratio</th>\n",
       "      <th>rr_ci_lo</th>\n",
       "      <th>rr_ci_hi</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>or_ci_lo</th>\n",
       "      <th>or_ci_hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.522709</td>\n",
       "      <td>-0.24177</td>\n",
       "      <td>0.462354</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.403</td>\n",
       "      <td>1.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>significance</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              beta_0      pi_0   beta_1      pi_1 risk_ratio  rr_ci_lo  \\\n",
       "value         0.0909  0.522709 -0.24177  0.462354      0.885      0.63   \n",
       "significance     NaN       NaN      NaN       NaN      False       NaN   \n",
       "\n",
       "              rr_ci_hi odds_ratio  or_ci_lo  or_ci_hi  \n",
       "value            1.242      0.785     0.403     1.528  \n",
       "significance       NaN      False       NaN       NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a df with GEE results\n",
    "\n",
    "gee_res_df = pd.DataFrame({\n",
    "    \"beta_0\": [beta_0, None],\n",
    "    \"pi_0\": [pi_0, None],\n",
    "    \"beta_1\": [beta_1, None],\n",
    "    \"pi_1\": [pi_1, None],\n",
    "    \"risk_ratio\": [round(rr_hat, 3), (gee_rr_cis[0] > 1) or (gee_rr_cis[1] < 1) if \"**\" else \"-\"],\n",
    "    \"rr_ci_lo\": [round(gee_rr_cis[0], 3), None],\n",
    "    \"rr_ci_hi\": [round(gee_rr_cis[1], 3), None],\n",
    "    \"odds_ratio\": [round(or_hat, 3), (gee_or_cis[0] > 1) or (gee_or_cis[1] < 1) if \"**\" else \"-\"],\n",
    "    \"or_ci_lo\": [round(gee_or_cis[0], 3), None],\n",
    "    \"or_ci_hi\": [round(gee_or_cis[1], 3), None]\n",
    "})\n",
    "\n",
    "gee_res_df = gee_res_df.rename(index={0: \"value\", 1: \"significance\"})\n",
    "gee_res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68748e67-9355-4d69-a812-4bf810451a08",
   "metadata": {},
   "source": [
    "Discussion here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881dd3d8-2993-490d-818a-4f35ed290455",
   "metadata": {},
   "source": [
    "### Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe44737b-41d7-4b3e-a49a-6167f46e9511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>brier_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bodhi</td>\n",
       "      <td>0.04580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Louis</td>\n",
       "      <td>0.08238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tom</td>\n",
       "      <td>0.15438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>0.19988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>May</td>\n",
       "      <td>0.21278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Evelyn</td>\n",
       "      <td>0.21834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kyle</td>\n",
       "      <td>0.21908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Harper</td>\n",
       "      <td>0.22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kerry</td>\n",
       "      <td>0.23138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tara</td>\n",
       "      <td>0.25558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  brier_score\n",
       "12          Bodhi      0.04580\n",
       "3          Louis       0.08238\n",
       "13            Tom      0.15438\n",
       "0           Wayne      0.19988\n",
       "24            May      0.21278\n",
       "18         Evelyn      0.21834\n",
       "11          Kyle       0.21908\n",
       "16        Harper       0.22650\n",
       "20          Kerry      0.23138\n",
       "21           Tara      0.25558"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brier score\n",
    "bs_results = data_df\n",
    "\n",
    "sample_cols = bs_results.filter(like=\"sample\")\n",
    "prediction_cols = bs_results.filter(like=\"prediction\")\n",
    "confidence_cols = bs_results.filter(like=\"confidence\")\n",
    "\n",
    "brier_rounds = ((sample_cols.values == prediction_cols.values).astype(int) - confidence_cols.values) ** 2\n",
    "brier_score = pd.DataFrame(brier_rounds).mean(axis=1)\n",
    "\n",
    "bs_results[\"brier_score\"] = brier_score\n",
    "bs_results = bs_results[[\"participant_id\", \"brier_score\"]].sort_values(by=\"brier_score\", ascending=True)\n",
    "\n",
    "bs_results.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3b091-fbfa-4a16-905b-713c8a0c264c",
   "metadata": {},
   "source": [
    "Discussion here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce3996-a377-4425-a128-b88d8c939c46",
   "metadata": {},
   "source": [
    "### Bayesian estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f351fdfc-0905-46f0-b3aa-28a35e3ff939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmdstanpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90171e1c-c87f-4f82-9e2b-55c306aea5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:52:44 - cmdstanpy - INFO - compiling stan file C:\\Users\\rosec\\OneDrive\\ACADEM~1\\coding\\Jupyter\\beta_binomial_model.stan to exe file C:\\Users\\rosec\\OneDrive\\Academic folder\\coding\\Jupyter\\beta_binomial_model.exe\n",
      "09:52:53 - cmdstanpy - INFO - compiled model executable: C:\\Users\\rosec\\OneDrive\\Academic folder\\coding\\Jupyter\\beta_binomial_model.exe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics and diagnostics for round1:\n",
      "\n",
      "               mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "p[treatment]  0.408  0.119   0.192    0.631      0.001    0.001    9223.0   \n",
      "p[control]    0.592  0.118   0.377    0.813      0.001    0.001    9000.0   \n",
      "risk_ratio    0.722  0.276   0.258    1.225      0.003    0.004    9046.0   \n",
      "odds_ratio    0.592  0.487   0.034    1.410      0.006    0.011    9159.0   \n",
      "\n",
      "              ess_tail  r_hat  \n",
      "p[treatment]    5950.0    1.0  \n",
      "p[control]      6513.0    1.0  \n",
      "risk_ratio      6288.0    1.0  \n",
      "odds_ratio      6163.0    1.0  \n",
      "\n",
      "Summary statistics and diagnostics for round2:\n",
      "\n",
      "               mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "p[treatment]  0.530  0.120   0.311    0.755      0.001    0.001    8665.0   \n",
      "p[control]    0.657  0.114   0.457    0.877      0.001    0.001    8867.0   \n",
      "risk_ratio    0.836  0.258   0.392    1.320      0.003    0.004    8193.0   \n",
      "odds_ratio    0.748  0.619   0.073    1.821      0.007    0.015    8238.0   \n",
      "\n",
      "              ess_tail  r_hat  \n",
      "p[treatment]    6743.0    1.0  \n",
      "p[control]      6519.0    1.0  \n",
      "risk_ratio      6324.0    1.0  \n",
      "odds_ratio      6168.0    1.0  \n",
      "\n",
      "Summary statistics and diagnostics for round3:\n",
      "\n",
      "               mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "p[treatment]  0.527  0.113   0.322    0.747      0.001    0.001   10298.0   \n",
      "p[control]    0.538  0.128   0.306    0.780      0.001    0.001    7367.0   \n",
      "risk_ratio    1.048  0.384   0.443    1.756      0.004    0.006    8566.0   \n",
      "odds_ratio    1.240  1.013   0.096    2.928      0.011    0.024    8590.0   \n",
      "\n",
      "              ess_tail  r_hat  \n",
      "p[treatment]    6069.0    1.0  \n",
      "p[control]      5934.0    1.0  \n",
      "risk_ratio      6292.0    1.0  \n",
      "odds_ratio      6074.0    1.0  \n",
      "\n",
      "Summary statistics and diagnostics for round4:\n",
      "\n",
      "               mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "p[treatment]  0.500  0.118   0.285    0.721      0.001    0.001    7618.0   \n",
      "p[control]    0.567  0.125   0.329    0.798      0.001    0.001    7843.0   \n",
      "risk_ratio    0.934  0.342   0.383    1.548      0.004    0.007    8113.0   \n",
      "odds_ratio    0.980  0.833   0.088    2.346      0.010    0.024    8065.0   \n",
      "\n",
      "              ess_tail  r_hat  \n",
      "p[treatment]    6117.0    1.0  \n",
      "p[control]      6270.0    1.0  \n",
      "risk_ratio      6429.0    1.0  \n",
      "odds_ratio      6380.0    1.0  \n",
      "\n",
      "Summary statistics and diagnostics for round5:\n",
      "\n",
      "               mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "p[treatment]  0.432  0.123   0.202    0.657      0.001    0.001    6968.0   \n",
      "p[control]    0.324  0.111   0.128    0.534      0.001    0.001    7397.0   \n",
      "risk_ratio    1.538  0.860   0.378    2.916      0.012    0.029    6647.0   \n",
      "odds_ratio    2.196  2.042   0.129    5.283      0.027    0.085    6855.0   \n",
      "\n",
      "              ess_tail  r_hat  \n",
      "p[treatment]    5709.0    1.0  \n",
      "p[control]      4860.0    1.0  \n",
      "risk_ratio      5860.0    1.0  \n",
      "odds_ratio      5787.0    1.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>p_1</th>\n",
       "      <th>p_2</th>\n",
       "      <th>risk_ratio</th>\n",
       "      <th>rr_lower</th>\n",
       "      <th>rr_upper</th>\n",
       "      <th>rr_significance</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>or_lower</th>\n",
       "      <th>or_upper</th>\n",
       "      <th>or_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round1</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.304</td>\n",
       "      <td>1.376</td>\n",
       "      <td>None</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.104</td>\n",
       "      <td>1.904</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round2</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.423</td>\n",
       "      <td>None</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.128</td>\n",
       "      <td>2.395</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>round3</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.497</td>\n",
       "      <td>1.989</td>\n",
       "      <td>None</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.225</td>\n",
       "      <td>3.895</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>round4</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1.764</td>\n",
       "      <td>None</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.175</td>\n",
       "      <td>3.127</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>round5</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.316</td>\n",
       "      <td>1.351</td>\n",
       "      <td>0.535</td>\n",
       "      <td>3.649</td>\n",
       "      <td>None</td>\n",
       "      <td>1.632</td>\n",
       "      <td>0.374</td>\n",
       "      <td>7.276</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round    p_1    p_2  risk_ratio  rr_lower  rr_upper rr_significance  \\\n",
       "1  round1  0.405  0.597       0.684     0.304     1.376            None   \n",
       "2  round2  0.532  0.663       0.805     0.422     1.423            None   \n",
       "3  round3  0.527  0.540       0.978     0.497     1.989            None   \n",
       "4  round4  0.501  0.571       0.882     0.445     1.764            None   \n",
       "5  round5  0.430  0.316       1.351     0.535     3.649            None   \n",
       "\n",
       "   odds_ratio  or_lower  or_upper or_significance  \n",
       "1       0.456     0.104     1.904            None  \n",
       "2       0.575     0.128     2.395            None  \n",
       "3       0.953     0.225     3.895            None  \n",
       "4       0.754     0.175     3.127            None  \n",
       "5       1.632     0.374     7.276            None  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian estimates\n",
    "    # Libraries\n",
    "import cmdstanpy\n",
    "import arviz as az\n",
    "import logging\n",
    "\n",
    "    # Stan script\n",
    "stan_script = \"\"\"\n",
    "data {\n",
    "    int<lower=1> K; // {treatment, control}\n",
    "    array[K] int<lower=0> n; // Trials per group\n",
    "    array[K] int<lower=0> y; // Successes per group\n",
    "}\n",
    "parameters {\n",
    "    vector<lower=0, upper=1>[K] p;\n",
    "}\n",
    "model {\n",
    "    // Jeffreys prior\n",
    "    p ~ beta(0.5, 0.5);\n",
    "\n",
    "    // Binomial likelihood\n",
    "    y ~ binomial(n, p);\n",
    "}\n",
    "generated quantities {\n",
    "    real risk_ratio = p[1] / p[2];\n",
    "    real odds_ratio = (p[1] / (1 - p[1])) / (p[2] / (1 - p[2]));\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    # Write the Stan model into a file\n",
    "with open('beta_binomial_model.stan', 'w') as f:\n",
    "    f.write(stan_script)\n",
    "    # Compile the model\n",
    "mod = cmdstanpy.CmdStanModel(stan_file='beta_binomial_model.stan')\n",
    "\n",
    "    # df\n",
    "bayes_df = pd.DataFrame({\n",
    "    \"round\": [],\n",
    "    \"p_1\": [],\n",
    "    \"p_2\":[],\n",
    "    \"risk_ratio\": [],\n",
    "    \"rr_lower\": [],\n",
    "    \"rr_upper\": [],\n",
    "    \"rr_significance\": [],\n",
    "    \"odds_ratio\": [],\n",
    "    \"or_lower\": [],\n",
    "    \"or_upper\": [],\n",
    "    \"or_significance\": []\n",
    "})\n",
    "\n",
    "    # Suppress the cmdstanpy MCMC readout\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
    "\n",
    "for name_i, contingency_table_i in df_dict.items():\n",
    "    idx = int(re.search(\"\\\\d{1}\", name_i).group())\n",
    "    ct = contingency_table_i.to_numpy()\n",
    "\n",
    "    stan_data = {\n",
    "        \"K\": 2, # {treatment, control}\n",
    "        \"n\": [sum(ct[0]), sum(ct[1])], # Trials per group\n",
    "        \"y\": [ct[0,0], ct[1,0]] # Successes per group\n",
    "    }\n",
    "\n",
    "    fit = mod.sample(\n",
    "        data = stan_data,\n",
    "        chains = 6,\n",
    "        parallel_chains = 6,\n",
    "        iter_warmup = int(4e2), # 4e3\n",
    "        iter_sampling = int(16e2), # 16e3\n",
    "        seed = 42,\n",
    "        refresh = None, # Suppresses progress updates\n",
    "        show_progress = False # Suppresses Stan messages\n",
    "    )\n",
    "\n",
    "    inference_data = az.from_cmdstanpy(\n",
    "        posterior = fit,\n",
    "        posterior_predictive = None,\n",
    "        coords={'group': ['treatment', 'control']},\n",
    "        dims={'p': ['group']}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSummary statistics and diagnostics for {name_i}:\\n\")\n",
    "    print(az.summary(inference_data))\n",
    "    # print(fit.summary()[['Mean', 'StdDev', 'R_hat']])\n",
    "    \n",
    "    # Extract posterior samples\n",
    "    posterior_draws_df = fit.draws_pd()\n",
    "    # posterior_draws = fit.draws() # numpy array\n",
    "\n",
    "    # Posterior summaries\n",
    "    draws_df = posterior_draws_df[[\"p[1]\", \"p[2]\", \"risk_ratio\", \"odds_ratio\"]]\n",
    "    rr_q = draws_df[\"risk_ratio\"].quantile([0.025, 0.5, 0.975]).values\n",
    "    or_q = draws_df[\"odds_ratio\"].quantile([0.025, 0.5, 0.975]).values\n",
    "\n",
    "    # Add the row to the df\n",
    "    bayes_df.loc[idx] = {\n",
    "        \"round\": name_i,\n",
    "        \"p_1\": round(draws_df[\"p[1]\"].median(), 3),\n",
    "        \"p_2\":round(draws_df[\"p[2]\"].median(), 3),\n",
    "        \"risk_ratio\": round(draws_df[\"risk_ratio\"].median(), 3),\n",
    "        \"rr_lower\": round(rr_q[0], 3),\n",
    "        \"rr_upper\": round(rr_q[2], 3),\n",
    "        \"rr_significance\": \"**\" if (rr_q[0] > 1) or (rr_q[2] < 1) else None,\n",
    "        \"odds_ratio\": round(draws_df[\"odds_ratio\"].median(), 3),\n",
    "        \"or_lower\": round(or_q[0], 3),\n",
    "        \"or_upper\": round(or_q[2], 3),\n",
    "        \"or_significance\": \"**\" if (or_q[0] > 1) or (or_q[2] < 1) else None\n",
    "    }\n",
    "    \n",
    "bayes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dba4a6-14e3-48bb-8cb8-88002c07c496",
   "metadata": {},
   "source": [
    "Discussion here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc16b44-c064-436f-afde-b4fc16777f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
