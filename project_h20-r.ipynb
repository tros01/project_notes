{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c30c7ec-4bd8-4b58-98ad-d794c07102f2",
   "metadata": {},
   "source": [
    "# The Unappealingly Titled Project H2O\n",
    "\n",
    "- R version (see folder for Python code)\n",
    "- work in progress\n",
    "\n",
    "## Objective\n",
    "\n",
    "We are primarily interested in participats' ability to discriminate between tap and potted water of some brand on average. In the second place, we are interested in assessing individuals' ability to identify the variety of the sample conditional on their confidence in their own prediction.\n",
    "\n",
    "## Methods\n",
    "\n",
    "The sampling process will span up to two months owing to constraints. The aim is to collect the largest sample attainable in up to five rounds per participant. See Sample collection below.\n",
    "\n",
    "The analysis will consist of four parts. We shall assess (i) the collective ability in each round using the relative risk and odds ratios based on (a) frequentist and (b) Bayesian estimates, (ii) the collective ability across rounds using generalised estimating equations, and (iii) the individual ability across rounds using a modified Brier score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91196ca-c4f4-4715-846d-72411680cd21",
   "metadata": {},
   "source": [
    "### Frequentist estimates\n",
    "\n",
    "The frequentist estimates are simple proportions of counts $n_{k1}$ in the marginal group counts $n_k$.\n",
    "\n",
    "|           | success (guessed potted water) $(g = 1)$ | failure (guessed tap water) $(g = 2)$ | sample margin |\n",
    "| --------- | ------- | ------- | ----- |\n",
    "| **treatment (sampled potted water)** $(s = 1)$ | $n_{11}$     | $n_{12}$     | $n_{s_p}=n_{11}+n_{12}$ |\n",
    "| **control (sampled tap water)** $(s = 2)$ | $n_{21}$     | $n_{22}$     | $n_{s_t}=n_{21}+n_{22}$ |\n",
    "| **guess margin** | $n_{g_p}=n_{11}+n_{21}$   | $n_{g_t}=n_{12}+n_{22}$   | $N=n_{11}+n_{12}+n_{21}+n_{22}$   |\n",
    "\n",
    "Then, estimators $\\hat{p}_1 = \\frac{1}{n_{s_p}} \\sum_{i=1}^{n_{s_p}} 1_{\\{g_i = 1\\}} = \\frac{n_{11}}{n_{s_p}}$ and $\\hat{p}_2 = \\frac{1}{n_{s_t}} \\sum_{i=1}^{n_{s_t}} 1_{\\{g_i = 1\\}} = \\frac{n_{21}}{n_{s_t}}$ solve the Bernoulli likelihood $\\mathcal{L}(p_k;y_k)=\\prod_{i=1}^{n_k}p_k^{y_{ki}}(1-p_k)^{1-y_{ki}}=p_k^{n_{k1}}(1-p_k)^{n_k-n_{k1}}$ where $n_{k1}$ is the count of successes in $n_{k}$ trials in sample group $k \\in \\{1,2\\}=\\{s_p,s_t\\}$ and individual outcomes $y_{ki}\\in \\{0,1\\}=\\{t,p\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f0fd0e-e751-4944-9aa5-547ae1cd2aa2",
   "metadata": {},
   "source": [
    "#### Risk and odds ratios\n",
    "\n",
    "| measure | estimator | null |\n",
    "|---------|-----------|------|\n",
    "| risk ratio | $\\rho=\\frac{p_1}{p_2}$ | $H_0:\\rho=\\rho_0=1$ |\n",
    "| odds ratio | $\\theta=\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}$ | $H_0:\\theta=\\theta_0=1$ |\n",
    "\n",
    "##### Risk ratio confidence intervals\n",
    "\n",
    "$$\n",
    "\\hat \\rho = \\frac{\\hat p_1}{\\hat p_2}, \\qquad\n",
    "\\log \\hat \\rho = \\log(\\hat p_1) - \\log(\\hat p_2).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widehat{\\text{SE}}(\\log \\hat \\rho)\n",
    "= \\sqrt{\\frac{1 - \\hat p_1}{\\hat p_1 n_{s_p}} + \\frac{1 - \\hat p_2}{\\hat p_2 n_{s_t}}}=\\sqrt{\\frac{1}{n_{11}} - \\frac{1}{n_{11}+n_{12}} + \\frac{1}{n_{21}} - \\frac{1}{n_{21}+n_{22}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\rho \\in \\exp{\\left( \\ln{\\hat{\\rho}}\\pm Z_{1-\\alpha/2}\\sqrt{\\widehat{\\text{SE}}(\\ln{\\hat{\\rho}})} \\right)}\n",
    "$$\n",
    "\n",
    "##### Odds ratio confidende intervals\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{n_{11} n_{22}}{n_{21} n_{12}}, \\quad\n",
    "\\log \\hat \\theta = \\log n_{11} + \\log n_{22} - \\log n_{12} - \\log n_{21},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widehat{\\text{SE}}(\\ln{\\hat{\\theta}})\n",
    "= \\sqrt{\\frac{1}{n_{11}}+\\frac{1}{n_{12}}+\\frac{1}{n_{21}}+\\frac{1}{n_{22}}}.\n",
    "$$\n",
    "\n",
    "Note that we commonly add $0.5$ to each $n_{kj}$ to avoid division by zero.\n",
    "\n",
    "$$\n",
    "\\theta \\in \\exp{\\left( \\ln{ \\hat \\theta \\pm Z_{1-\\alpha/2}\\ \\widehat{\\mathrm{SE}}(\\ln{\\hat{\\theta}}) } \\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb8631-140c-49f9-acce-8625508e5315",
   "metadata": {},
   "source": [
    "### Bayesian estimates\n",
    "\n",
    "We shall use a standard beta-binomial setup with conjugate priors. This is generally summarised with the continuous form of the Bayes rule like so,\n",
    "\n",
    "$$\n",
    "f(\\theta \\mid y) = \\frac{\\prod_{i=1}^{n_k} g(y \\mid \\theta) f(\\theta)}{\\int g(y \\mid \\theta) f(\\theta) \\, d\\theta}\n",
    "$$\n",
    "\n",
    "We set up the model like so, \n",
    "\n",
    "- $y_k \\mid p_k \\sim \\text{binomial}(n_k, p_k), \\text{for } k=1,2$ (likelihood)\n",
    "- $p_k \\sim \\text{Beta}(\\alpha, \\beta)$, choose non-informative $p_k \\sim \\text{Beta}(\\frac{1}{2}, \\frac{1}{2})$ (Jeffreys prior) \n",
    "- $p_k \\mid y_k \\sim \\text{Beta}(y_k+\\alpha,n_k-y_k+\\beta) = \\text{Beta}(\\frac{1}{2}+y_k,\\frac{1}{2}+n_k-y_k)$ (implied posterior)\n",
    "\n",
    "Hence the posterior,\n",
    "\n",
    "$$\n",
    "f(p_k \\mid y_k) \\propto \\mathcal{L}(p_k;y_k) f(p_k) = \\left(p_k^{y_k}(1-p_k)^{n_k-y_k}\\right)\\left(p_k^{\\frac{1}{2}-1}(1-p_k)^{\\frac{1}{2}-1}\\right) = p_k^{y_k-\\frac{1}{2}}(1-p_k)^{n_k-y_k-\\frac{1}{2}}\n",
    "$$\n",
    "\n",
    "We shall run 16e4 simulations with an additional 4e4 burnin in six chains, and we are interested in the median and the 95% credible interval. We use the estimates to compute the risk and odds ratios and the respective credible intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81aa35-0526-4e8d-bd3a-ac85a15ffc80",
   "metadata": {},
   "source": [
    "### Generalised estimating equations\n",
    "\n",
    "Generalised estimating equations approximate the (marginal) population-average effect for our clustered sample of $i=1,...,M$ individuals across $j=1,...,5$ rounds. The GEE algorithm internally adjusts for correlated data.\n",
    "\n",
    "The results are interpreted as a binomial logit model like so,\n",
    "\n",
    "$$\n",
    "\\text{logit}\\left(\\pi_{ij}\\right)=\\ln{\\left(\\frac{\\pi_{ij}}{1-\\pi_{ij}}\\right)}=\\beta_0+\\beta_1 x_{ij}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "- $\\pi_{ij}=P(Y_{ij}=1)=\\mathbb{E}\\left[Y_{ij} \\mid X_{ij} \\right]=\\text{logit}^{-1}(X_{ij}'\\beta)$ is the probability that participant $i$ gets predicts potted water ($g=1$) in round $j$\n",
    "- $\\frac{\\pi_{ij}}{1-\\pi_{ij}}$ is the odds of predicting potted water ($g=1$)\n",
    "- $\\beta_0$ is the log-odds when $x_{ij} = 0$ (intercept)\n",
    "- $\\beta_1$ is the effect of $x_{ij} = 1$ on the log-odds\n",
    "\n",
    "GEE solve the following gradient for $\\beta$,\n",
    "\n",
    "$$\n",
    "U(\\beta)=\\sum_{i=1}^N D_i'V_i^{-1}(y_i-\\mu_i)=0\n",
    "$$\n",
    "\n",
    "Where $D_i=\\frac{\\partial \\pi_i}{\\partial \\beta'}=A_i X_i$ with $A_i = \\text{diag}\\left(v(\\mu_{it})\\right)$ and the working covariance,\n",
    "\n",
    "$$\n",
    "V_i = \\phi A_i^{1/2},R(\\alpha),A_i^{1/2},\\quad\n",
    "A_i=\\text{diag}\\,\\left(\\pi_{ij}(1-\\pi_{ij})\\right)\n",
    "$$\n",
    "\n",
    "Where $R(\\alpha_i)=\\left[\\begin{matrix} 1 & \\alpha & \\alpha & \\dots & \\alpha \\\\ \\alpha & 1 & \\alpha & \\dots & \\alpha \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ \\alpha & \\alpha & \\dots & 1\\end{matrix}\\right]$ is the exchangeable working correlation structure. No closed form exists. The algorithm solves the system iteratively.\n",
    "\n",
    "#### Retrieve probabilities\n",
    "\n",
    "$$\n",
    "\\pi_0=\\text{logit}^{-1}(\\beta_0)=\\frac{1}{1+e^{-\\beta_0}}=1-\\frac{1}{1+e^{\\beta_0}}=\\text{plogis}(\\beta_0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi_1=\\text{logit}^{-1}(\\beta_0 + \\beta_1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1)}}=1-\\frac{1}{1+e^{\\beta_0+\\beta_1}}=\\text{plogis}(\\beta_0 + \\beta_1)\n",
    "$$\n",
    "\n",
    "#### Relative risk\n",
    "\n",
    "$$\n",
    "\\hat{\\rho}=\\frac{\\hat{\\pi}_1}{\\hat{\\pi}_0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln{(\\hat{\\rho})}=\\ln{\\left(\\frac{\\pi_1(\\beta)}{\\pi_0(\\beta)}\\right)}=\\ln{\\left(\\frac{\\text{logit}^{-1}(\\beta_0+\\beta_1)}{\\text{logit}^{-1}(\\beta_0)}\\right)}\n",
    "$$\n",
    "\n",
    "With confidence intervals,\n",
    "\n",
    "$$\n",
    "\\rho \\in \\exp{\\left(\\ln{\\hat{\\rho}}\\pm Z_{1-\\alpha/2}\\,\\widehat{\\text{SE}}(\\ln{\\hat{\\rho}})\\right)}, \\quad\n",
    "\\text{Var}\\left(\\ln{\\hat{\\rho}}\\right)\\approx g'\\widehat{\\text{Var}}_{\\text{gp}}(\\hat{\\beta})g, \\quad\n",
    "g=\\left[\\begin{matrix}\\frac{\\partial\\ln{\\hat{\\rho}}}{\\partial\\beta_0} \\\\ \\frac{\\partial\\ln{\\hat{\\rho}}}{\\partial\\beta_1}\\end{matrix}\\right]=\\left[\\begin{matrix}\\hat{\\pi}_0-\\hat{\\pi}_1 \\\\ 1-\\hat{\\pi}_1\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "#### Odds ratio\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}=\\frac{\\hat{\\pi}_1/1-\\hat{\\pi}_1}{\\hat{\\pi}_0/1-\\hat{\\pi}_0}\n",
    "$$\n",
    "\n",
    "With confidence intervals,\n",
    "\n",
    "$$\n",
    "\\theta \\in \\exp{\\left(\\ln{\\hat{\\theta}}\\pm Z_{1-\\alpha/2}\\,\\text{SE}(\\ln{\\hat{\\beta}})\\right)}, \\quad \\text{SE}(\\ln{\\hat{\\beta}})=\\text{SE}(\\ln{\\hat{\\theta}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c1fe7-0ee2-4f71-ba33-6452a563b7bb",
   "metadata": {},
   "source": [
    "### Brier score\n",
    "\n",
    "The typical Brier score for a set of clustered outcomes and predictions for $j=1,...,J$ measures the accuracy of the participant's predictions as follows,\n",
    "\n",
    "$$\n",
    "\\text{BS}=\\frac{1}{n}\\sum_{j=1}^J (P_j - 1_{\\{X_j = 1\\}})^2\n",
    "$$\n",
    "\n",
    "Where $P_j \\in [0,1]$ is a measure of the participant's confidence in the outcome $X_j \\in \\{0,1\\}$. Particularly $P_j \\to 1$ implies higher confidence in $X_j = 1$ and $P_j \\to 0$ implies a lower confidence in $X_j = 1$. Lower $BS$ imply a higher accuracy. See Brier (1950).\n",
    "\n",
    "This can be reconceived as a measure of confidence like so,\n",
    "\n",
    "$$\n",
    "\\text{BS}=\\frac{1}{n}\\sum_{j=1}^J (Z_j - 1_{\\{S_j = 1\\}})^2, \\quad\n",
    "S_j =\n",
    "\\begin{cases}\n",
    "1, & X_j = Y_j,\\\\\n",
    "0, & X_j \\neq Y_j\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $X_j \\in {\\{0,1\\}}$ denotes the outcome, $Y_j \\in {\\{0,1\\}}$ denotes the categorical prediction, $S_j \\in {\\{0,1\\}}$ is the correctnes indicator and $Z_j \\in [0,1]$ is the confidence level indicator. The participant then predicts the outcome $Y_j$ with a level of confidence $Z_j$ on a continuous scale from 0% (not at all confident) to 100% (absolutely certain). Once more a lower $BS$ implies a higher accuracy. See Juslin (1994) for a similar setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4584d-e9a5-453b-aa71-04b26590543e",
   "metadata": {},
   "source": [
    "## Sample collection\n",
    "\n",
    "The samples will be collected in $k=1,...,5$ rounds per each individual $i$ in $n$ participants. In each round $k$, each participant $i$ will be randomly assigned to group $T$ (tap water) or $P$ (potted water). This assignment will be carried out by a draw from the Bernoulli distribution with $p=\\frac{1}{2}$. An ordered set of 100 values $0$ ($T$) and $1$ ($P$) will be generated every Monday and each participant will be allotted $0$ or $1$ on a first come first serve basis.\n",
    "\n",
    "Each round will use a different brand of potted water - Evian, Volvic, Highland Spring, Buxton, Waitrose Essentials - and unfiltered tap water drawn from the same tap. Both will be cooled to the like temperature overnight at most. Samples will be poured from reusable vessels and tasted from disposable cups.\n",
    "\n",
    "For each participant, we record (I) an identifier (first name), (II) the water sample tasted ($0$ or $1$), (III) the guess ($T$ or $P$), and (IV) level of confidence ([$0,100%$] from not at all confident to absolutely certain).\n",
    "\n",
    "The participant with the most accurate score across all five rounds wins six bottles of the potted water that has done best against the tap water. In case of more than one winner, a draw from the uniform distribution decides.\n",
    "\n",
    "The sample collection is expected to conclude by the end of November 2025. The results ought to follow by mid-December.\n",
    "\n",
    "Caveats: Logistic difficulties preclude the application of a double blind test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bd2c0-8fa2-419a-b182-7368782f79f2",
   "metadata": {},
   "source": [
    "## Reference material\n",
    "\n",
    "Agresti, A. (2019) *An Introduction to Categorical Data Analysis*, 3rd edn. Wiley.\n",
    "\n",
    "Agresti, A. (2002) *Categorical Data Analysis*, 2nd edn. Wiley.\n",
    "\n",
    "Brier, G.W. (1950) 'Verification of Forecasts Expressed in Terms of Probability'. *Monthly Weather Review*, Volume 78, Number 1. https://web.archive.org/web/20171023012737/https://docs.lib.noaa.gov/rescue/mwr/078/mwr-078-01-0001.pdf\n",
    "\n",
    "Ford, C. (2023) 'Getting Started with Generalized Estimating Equations'. University of Virginia Library. https://library.virginia.edu/data/articles/getting-started-with-generalized-estimating-equations\n",
    "\n",
    "Goldstein-Greenwood, J. (2021) 'A Brief on Brier Scores'. University of Virginia Library. https://library.virginia.edu/data/articles/a-brief-on-brier-scores\n",
    "\n",
    "Halekoh, U., Højsgaard, S. and Yan, J. (2006) 'The R Package geepack for Generalized Estimating Equations'. *Journal of Statistical Software', January 2006, Volume 15, Issue 2. DOI:10.18637/jss.v015.i02\n",
    "\n",
    "Hardin, J.W. and Hilbe, J.M. (2013) *Generalised Estimating Equations*, 2nd edn. CRC Press.\n",
    "\n",
    "Hoessly, L. (2025) 'On misconceptions about the Brier score in binary prediction models'. arXiv. https://arxiv.org/html/2504.04906v3\n",
    "\n",
    "Hoff, P.D. (2009) *A First Course in Bayesian Statistical Methods*. Springer.\n",
    "\n",
    "Højsgaard, S., Halekoh, U., Yan, J., Ekstrøm, C.T. (2025) 'geepack: Generalized Estimating Equation Package'. https://cran.r-project.org/web/packages/geepack/index.html\n",
    "\n",
    "Juslin, P. (1994) 'The Overconfidence Phenomenon as a Consequence of Informal Experimenter-Guided Selection of Almanac Items'. *Organizational Behavior and Human Decision Processes* 57, 226-246.\n",
    "\n",
    "Marin, J.M. and Robert, C. (2014) *Bayesian Essentials with R*, 2nd edn. Springer.\n",
    "\n",
    "Matsuura, K. (2022) *Bayesian Statistical Modeling with Stan, R, and Python*. Springer.\n",
    "\n",
    "Robert, D. (2020) 'Five Confidence Intervals for Proportions That You Should Know About'. Towards Data Science. https://towardsdatascience.com/five-confidence-intervals-for-proportions-that-you-should-know-about-7ff5484c024f/\n",
    "\n",
    "Stan Development Team (2024) 'Documentation'. https://mc-stan.org/docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff0902-2c59-4954-95ec-4374a63b338f",
   "metadata": {},
   "source": [
    "## Machinery check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a9a331-7953-45a3-bebe-1bb822869d1d",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.1.0     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(readxl)\n",
    "\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6d906-ff3f-4a5c-a6d6-071de7ff39da",
   "metadata": {},
   "source": [
    "### Data structure and mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cf28c9-3329-42fb-a598-63284d823b08",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"participant_id\"    \"round1_sample\"     \"round1_prediction\"\n",
      " [4] \"round1_confidence\" \"round2_sample\"     \"round2_prediction\"\n",
      " [7] \"round2_confidence\" \"round3_sample\"     \"round3_prediction\"\n",
      "[10] \"round3_confidence\" \"round4_sample\"     \"round4_prediction\"\n",
      "[13] \"round4_confidence\" \"round5_sample\"     \"round5_prediction\"\n",
      "[16] \"round5_confidence\"\n"
     ]
    }
   ],
   "source": [
    "# Construct a data frame\n",
    "rounds <- 5\n",
    "\n",
    "df <- tibble(\n",
    "    participant_id = character()\n",
    ")\n",
    "\n",
    "for (i in seq(rounds)) {\n",
    "    col1 <- paste0(\"round\", i, \"_sample\")\n",
    "    col2 <- paste0(\"round\", i, \"_prediction\")\n",
    "    col3 <- paste0(\"round\", i, \"_confidence\")\n",
    "\n",
    "    df <- df |>\n",
    "        mutate(\n",
    "            !!col1 := integer(),\n",
    "            !!col2 := integer(),\n",
    "            !!col3 := numeric()\n",
    "        )\n",
    "}\n",
    "\n",
    "df |> colnames() |> print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c453d9fd-d3f4-4b0c-8655-53a648b291c6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 10 × 16</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>participant_id</th><th scope=col>round1_sample</th><th scope=col>round1_prediction</th><th scope=col>round1_confidence</th><th scope=col>round2_sample</th><th scope=col>round2_prediction</th><th scope=col>round2_confidence</th><th scope=col>round3_sample</th><th scope=col>round3_prediction</th><th scope=col>round3_confidence</th><th scope=col>round4_sample</th><th scope=col>round4_prediction</th><th scope=col>round4_confidence</th><th scope=col>round5_sample</th><th scope=col>round5_prediction</th><th scope=col>round5_confidence</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Victor  </td><td>0</td><td>0</td><td>0.00</td><td>1</td><td>0</td><td>0.73</td><td>0</td><td>1</td><td>0.03</td><td>0</td><td>1</td><td>0.83</td><td>0</td><td>0</td><td>0.86</td></tr>\n",
       "\t<tr><td>Patricia</td><td>1</td><td>1</td><td>0.61</td><td>0</td><td>1</td><td>0.89</td><td>0</td><td>0</td><td>0.87</td><td>0</td><td>0</td><td>0.58</td><td>1</td><td>0</td><td>0.35</td></tr>\n",
       "\t<tr><td>George  </td><td>0</td><td>0</td><td>0.84</td><td>0</td><td>0</td><td>0.52</td><td>1</td><td>0</td><td>0.73</td><td>0</td><td>0</td><td>0.47</td><td>0</td><td>0</td><td>0.00</td></tr>\n",
       "\t<tr><td>Stanley </td><td>1</td><td>1</td><td>0.75</td><td>1</td><td>1</td><td>0.85</td><td>1</td><td>0</td><td>0.32</td><td>0</td><td>1</td><td>0.37</td><td>0</td><td>1</td><td>0.91</td></tr>\n",
       "\t<tr><td>Eileen  </td><td>1</td><td>0</td><td>0.45</td><td>0</td><td>1</td><td>0.44</td><td>0</td><td>1</td><td>0.39</td><td>1</td><td>1</td><td>0.28</td><td>1</td><td>0</td><td>0.95</td></tr>\n",
       "\t<tr><td>Lucas   </td><td>1</td><td>0</td><td>0.54</td><td>0</td><td>0</td><td>0.16</td><td>0</td><td>1</td><td>0.33</td><td>0</td><td>1</td><td>0.60</td><td>1</td><td>0</td><td>0.49</td></tr>\n",
       "\t<tr><td>Katie   </td><td>1</td><td>1</td><td>0.54</td><td>0</td><td>1</td><td>0.44</td><td>0</td><td>0</td><td>0.09</td><td>1</td><td>0</td><td>0.82</td><td>0</td><td>1</td><td>0.46</td></tr>\n",
       "\t<tr><td>Alec    </td><td>0</td><td>1</td><td>0.00</td><td>1</td><td>0</td><td>0.97</td><td>0</td><td>1</td><td>0.76</td><td>0</td><td>0</td><td>0.10</td><td>0</td><td>1</td><td>0.60</td></tr>\n",
       "\t<tr><td>Arthur  </td><td>1</td><td>0</td><td>0.36</td><td>1</td><td>1</td><td>0.48</td><td>1</td><td>0</td><td>0.60</td><td>1</td><td>0</td><td>0.96</td><td>1</td><td>0</td><td>0.91</td></tr>\n",
       "\t<tr><td>Hannah  </td><td>0</td><td>0</td><td>0.61</td><td>0</td><td>1</td><td>0.25</td><td>1</td><td>1</td><td>0.15</td><td>1</td><td>1</td><td>0.17</td><td>0</td><td>0</td><td>0.17</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 10 × 16\n",
       "\\begin{tabular}{llllllllllllllll}\n",
       " participant\\_id & round1\\_sample & round1\\_prediction & round1\\_confidence & round2\\_sample & round2\\_prediction & round2\\_confidence & round3\\_sample & round3\\_prediction & round3\\_confidence & round4\\_sample & round4\\_prediction & round4\\_confidence & round5\\_sample & round5\\_prediction & round5\\_confidence\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Victor   & 0 & 0 & 0.00 & 1 & 0 & 0.73 & 0 & 1 & 0.03 & 0 & 1 & 0.83 & 0 & 0 & 0.86\\\\\n",
       "\t Patricia & 1 & 1 & 0.61 & 0 & 1 & 0.89 & 0 & 0 & 0.87 & 0 & 0 & 0.58 & 1 & 0 & 0.35\\\\\n",
       "\t George   & 0 & 0 & 0.84 & 0 & 0 & 0.52 & 1 & 0 & 0.73 & 0 & 0 & 0.47 & 0 & 0 & 0.00\\\\\n",
       "\t Stanley  & 1 & 1 & 0.75 & 1 & 1 & 0.85 & 1 & 0 & 0.32 & 0 & 1 & 0.37 & 0 & 1 & 0.91\\\\\n",
       "\t Eileen   & 1 & 0 & 0.45 & 0 & 1 & 0.44 & 0 & 1 & 0.39 & 1 & 1 & 0.28 & 1 & 0 & 0.95\\\\\n",
       "\t Lucas    & 1 & 0 & 0.54 & 0 & 0 & 0.16 & 0 & 1 & 0.33 & 0 & 1 & 0.60 & 1 & 0 & 0.49\\\\\n",
       "\t Katie    & 1 & 1 & 0.54 & 0 & 1 & 0.44 & 0 & 0 & 0.09 & 1 & 0 & 0.82 & 0 & 1 & 0.46\\\\\n",
       "\t Alec     & 0 & 1 & 0.00 & 1 & 0 & 0.97 & 0 & 1 & 0.76 & 0 & 0 & 0.10 & 0 & 1 & 0.60\\\\\n",
       "\t Arthur   & 1 & 0 & 0.36 & 1 & 1 & 0.48 & 1 & 0 & 0.60 & 1 & 0 & 0.96 & 1 & 0 & 0.91\\\\\n",
       "\t Hannah   & 0 & 0 & 0.61 & 0 & 1 & 0.25 & 1 & 1 & 0.15 & 1 & 1 & 0.17 & 0 & 0 & 0.17\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 10 × 16\n",
       "\n",
       "| participant_id &lt;chr&gt; | round1_sample &lt;dbl&gt; | round1_prediction &lt;dbl&gt; | round1_confidence &lt;dbl&gt; | round2_sample &lt;dbl&gt; | round2_prediction &lt;dbl&gt; | round2_confidence &lt;dbl&gt; | round3_sample &lt;dbl&gt; | round3_prediction &lt;dbl&gt; | round3_confidence &lt;dbl&gt; | round4_sample &lt;dbl&gt; | round4_prediction &lt;dbl&gt; | round4_confidence &lt;dbl&gt; | round5_sample &lt;dbl&gt; | round5_prediction &lt;dbl&gt; | round5_confidence &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Victor   | 0 | 0 | 0.00 | 1 | 0 | 0.73 | 0 | 1 | 0.03 | 0 | 1 | 0.83 | 0 | 0 | 0.86 |\n",
       "| Patricia | 1 | 1 | 0.61 | 0 | 1 | 0.89 | 0 | 0 | 0.87 | 0 | 0 | 0.58 | 1 | 0 | 0.35 |\n",
       "| George   | 0 | 0 | 0.84 | 0 | 0 | 0.52 | 1 | 0 | 0.73 | 0 | 0 | 0.47 | 0 | 0 | 0.00 |\n",
       "| Stanley  | 1 | 1 | 0.75 | 1 | 1 | 0.85 | 1 | 0 | 0.32 | 0 | 1 | 0.37 | 0 | 1 | 0.91 |\n",
       "| Eileen   | 1 | 0 | 0.45 | 0 | 1 | 0.44 | 0 | 1 | 0.39 | 1 | 1 | 0.28 | 1 | 0 | 0.95 |\n",
       "| Lucas    | 1 | 0 | 0.54 | 0 | 0 | 0.16 | 0 | 1 | 0.33 | 0 | 1 | 0.60 | 1 | 0 | 0.49 |\n",
       "| Katie    | 1 | 1 | 0.54 | 0 | 1 | 0.44 | 0 | 0 | 0.09 | 1 | 0 | 0.82 | 0 | 1 | 0.46 |\n",
       "| Alec     | 0 | 1 | 0.00 | 1 | 0 | 0.97 | 0 | 1 | 0.76 | 0 | 0 | 0.10 | 0 | 1 | 0.60 |\n",
       "| Arthur   | 1 | 0 | 0.36 | 1 | 1 | 0.48 | 1 | 0 | 0.60 | 1 | 0 | 0.96 | 1 | 0 | 0.91 |\n",
       "| Hannah   | 0 | 0 | 0.61 | 0 | 1 | 0.25 | 1 | 1 | 0.15 | 1 | 1 | 0.17 | 0 | 0 | 0.17 |\n",
       "\n"
      ],
      "text/plain": [
       "   participant_id round1_sample round1_prediction round1_confidence\n",
       "1  Victor         0             0                 0.00             \n",
       "2  Patricia       1             1                 0.61             \n",
       "3  George         0             0                 0.84             \n",
       "4  Stanley        1             1                 0.75             \n",
       "5  Eileen         1             0                 0.45             \n",
       "6  Lucas          1             0                 0.54             \n",
       "7  Katie          1             1                 0.54             \n",
       "8  Alec           0             1                 0.00             \n",
       "9  Arthur         1             0                 0.36             \n",
       "10 Hannah         0             0                 0.61             \n",
       "   round2_sample round2_prediction round2_confidence round3_sample\n",
       "1  1             0                 0.73              0            \n",
       "2  0             1                 0.89              0            \n",
       "3  0             0                 0.52              1            \n",
       "4  1             1                 0.85              1            \n",
       "5  0             1                 0.44              0            \n",
       "6  0             0                 0.16              0            \n",
       "7  0             1                 0.44              0            \n",
       "8  1             0                 0.97              0            \n",
       "9  1             1                 0.48              1            \n",
       "10 0             1                 0.25              1            \n",
       "   round3_prediction round3_confidence round4_sample round4_prediction\n",
       "1  1                 0.03              0             1                \n",
       "2  0                 0.87              0             0                \n",
       "3  0                 0.73              0             0                \n",
       "4  0                 0.32              0             1                \n",
       "5  1                 0.39              1             1                \n",
       "6  1                 0.33              0             1                \n",
       "7  0                 0.09              1             0                \n",
       "8  1                 0.76              0             0                \n",
       "9  0                 0.60              1             0                \n",
       "10 1                 0.15              1             1                \n",
       "   round4_confidence round5_sample round5_prediction round5_confidence\n",
       "1  0.83              0             0                 0.86             \n",
       "2  0.58              1             0                 0.35             \n",
       "3  0.47              0             0                 0.00             \n",
       "4  0.37              0             1                 0.91             \n",
       "5  0.28              1             0                 0.95             \n",
       "6  0.60              1             0                 0.49             \n",
       "7  0.82              0             1                 0.46             \n",
       "8  0.10              0             1                 0.60             \n",
       "9  0.96              1             0                 0.91             \n",
       "10 0.17              0             0                 0.17             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate mock data\n",
    "    # Load up some names\n",
    "url <- r\"(https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/datasets/babynamesenglandandwalestop100babynameshistoricaldata/1904to2024/historicalnames2024.xlsx)\"\n",
    "download.file(url, \"historicalnames2024.xlsx\", mode = \"wb\")\n",
    "\n",
    "data_g <- read_excel(\"historicalnames2024.xlsx\", sheet = \"Table_1\", skip = 3)\n",
    "data_b <- read_excel(\"historicalnames2024.xlsx\", sheet = \"Table_2\", skip = 3)\n",
    "\n",
    "df_names <- data_g |>\n",
    "    janitor::clean_names() |>\n",
    "    add_row(\n",
    "        data_b |> \n",
    "        janitor::clean_names()\n",
    "    ) |> \n",
    "    select(-rank) |>\n",
    "    pivot_longer(\n",
    "        cols = everything(), \n",
    "        names_to = \"var\", \n",
    "        values_to = \"val\"\n",
    "    ) |>\n",
    "    filter(!(is.na(val)))\n",
    "\n",
    "    # Construct a mock df\n",
    "df_cols <- colnames(df)\n",
    "no_samples <- 30 # Sample size\n",
    "\n",
    "mock_df <- tibble(\n",
    "    # Random ids (names)\n",
    "    !!df_cols[1] := sample(df_names$val, no_samples, replace = TRUE)\n",
    ")\n",
    "\n",
    "for (i in seq(2, length(df_cols), 3)) {\n",
    "    # Water sample ~ Bern(0.5) with 0 (tap), 1 (potted)\n",
    "    mock_df[df_cols[i]] <- sample(c(0,1), no_samples, replace = TRUE)\n",
    "    # Participant guess: 0 (tap), 1 (potted)\n",
    "    mock_df[df_cols[i + 1]] <- sample(c(0,1), no_samples, replace = TRUE)\n",
    "    # Participant confidence ~ U(0,1)\n",
    "    mock_df[df_cols[i + 2]] <- round(runif(no_samples, 0, 1), 2)\n",
    "}\n",
    "\n",
    "mock_df |> head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78952529-1244-438f-85b4-1475f2c99734",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plug in the data\n",
    "data_df <- mock_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262c20c-baf9-4e91-8004-bf3c9d72df21",
   "metadata": {},
   "source": [
    "#### Contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc16f44f-d524-44ed-b129-d499606d97af",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 2 × 3\u001b[39m\n",
      "  sample   guess_t guess_p\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m sample_0       6       6\n",
      "\u001b[90m2\u001b[39m sample_1       7      11\n",
      "\u001b[90m# A tibble: 2 × 3\u001b[39m\n",
      "  sample   guess_t guess_p\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m sample_0       7      10\n",
      "\u001b[90m2\u001b[39m sample_1       2      11\n",
      "\u001b[90m# A tibble: 2 × 3\u001b[39m\n",
      "  sample   guess_t guess_p\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m sample_0      11       7\n",
      "\u001b[90m2\u001b[39m sample_1       7       5\n",
      "\u001b[90m# A tibble: 2 × 3\u001b[39m\n",
      "  sample   guess_t guess_p\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m sample_0       8       7\n",
      "\u001b[90m2\u001b[39m sample_1       9       6\n",
      "\u001b[90m# A tibble: 2 × 3\u001b[39m\n",
      "  sample   guess_t guess_p\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m sample_0       8       5\n",
      "\u001b[90m2\u001b[39m sample_1       9       8\n"
     ]
    }
   ],
   "source": [
    "# Round dfs\n",
    "df_list <- list()\n",
    "df_counter <- 0\n",
    "\n",
    "for (i in seq(2, length(df_cols), 3)) {\n",
    "    df_counter <- df_counter + 1\n",
    "\n",
    "    samp <- df_cols[i]\n",
    "    pred <- df_cols[i + 1]\n",
    "    df_name <- paste0(\"round\", df_counter)\n",
    "    \n",
    "    df_list[[df_name]] <- tibble(\n",
    "        guess_t = c(\n",
    "            # True negatives\n",
    "            sum((data_df[[samp]] == 0) & (data_df[[pred]] == 0)),\n",
    "            # False negatives\n",
    "            sum((data_df[[samp]] == 1) & (data_df[[pred]] == 0))\n",
    "        ),\n",
    "        guess_p = c(\n",
    "            # False positives\n",
    "            sum((data_df[[samp]] == 0) & (data_df[[pred]] == 1)),\n",
    "            # True positives\n",
    "            sum((data_df[[samp]] == 1) & (data_df[[pred]] == 1))\n",
    "        )\n",
    "    ) |>\n",
    "    add_column(sample = c(\"sample_0\", \"sample_1\"), .before = 1)\n",
    "\n",
    "    df_list[[df_name]] |> print()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df509be5-274d-4bdf-a73e-146a51e61720",
   "metadata": {},
   "source": [
    "### Frequentist estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9fc2a50-9ed0-4ae7-a2aa-a78b94e78103",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>round</th><th scope=col>relative_risk</th><th scope=col>rr_ci_lower</th><th scope=col>rr_ci_upper</th><th scope=col>rr_significance</th><th scope=col>odds_ratio</th><th scope=col>or_ci_lower</th><th scope=col>or_ci_upper</th><th scope=col>or_significance</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>round1</td><td>1.2857</td><td>0.5722</td><td> 2.8891</td><td>NA</td><td>1.5714</td><td>0.3592</td><td> 6.8754</td><td>NA</td></tr>\n",
       "\t<tr><td>round2</td><td>2.6765</td><td>0.6628</td><td>10.8073</td><td>NA</td><td>3.8500</td><td>0.6430</td><td>23.0515</td><td>NA</td></tr>\n",
       "\t<tr><td>round3</td><td>1.0476</td><td>0.5728</td><td> 1.9160</td><td>NA</td><td>1.1224</td><td>0.2534</td><td> 4.9720</td><td>NA</td></tr>\n",
       "\t<tr><td>round4</td><td>0.8889</td><td>0.4742</td><td> 1.6662</td><td>NA</td><td>0.7619</td><td>0.1791</td><td> 3.2408</td><td>NA</td></tr>\n",
       "\t<tr><td>round5</td><td>1.1624</td><td>0.6247</td><td> 2.1628</td><td>NA</td><td>1.4222</td><td>0.3276</td><td> 6.1742</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " round & relative\\_risk & rr\\_ci\\_lower & rr\\_ci\\_upper & rr\\_significance & odds\\_ratio & or\\_ci\\_lower & or\\_ci\\_upper & or\\_significance\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <chr> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t round1 & 1.2857 & 0.5722 &  2.8891 & NA & 1.5714 & 0.3592 &  6.8754 & NA\\\\\n",
       "\t round2 & 2.6765 & 0.6628 & 10.8073 & NA & 3.8500 & 0.6430 & 23.0515 & NA\\\\\n",
       "\t round3 & 1.0476 & 0.5728 &  1.9160 & NA & 1.1224 & 0.2534 &  4.9720 & NA\\\\\n",
       "\t round4 & 0.8889 & 0.4742 &  1.6662 & NA & 0.7619 & 0.1791 &  3.2408 & NA\\\\\n",
       "\t round5 & 1.1624 & 0.6247 &  2.1628 & NA & 1.4222 & 0.3276 &  6.1742 & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 9\n",
       "\n",
       "| round &lt;chr&gt; | relative_risk &lt;dbl&gt; | rr_ci_lower &lt;dbl&gt; | rr_ci_upper &lt;dbl&gt; | rr_significance &lt;chr&gt; | odds_ratio &lt;dbl&gt; | or_ci_lower &lt;dbl&gt; | or_ci_upper &lt;dbl&gt; | or_significance &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| round1 | 1.2857 | 0.5722 |  2.8891 | NA | 1.5714 | 0.3592 |  6.8754 | NA |\n",
       "| round2 | 2.6765 | 0.6628 | 10.8073 | NA | 3.8500 | 0.6430 | 23.0515 | NA |\n",
       "| round3 | 1.0476 | 0.5728 |  1.9160 | NA | 1.1224 | 0.2534 |  4.9720 | NA |\n",
       "| round4 | 0.8889 | 0.4742 |  1.6662 | NA | 0.7619 | 0.1791 |  3.2408 | NA |\n",
       "| round5 | 1.1624 | 0.6247 |  2.1628 | NA | 1.4222 | 0.3276 |  6.1742 | NA |\n",
       "\n"
      ],
      "text/plain": [
       "  round  relative_risk rr_ci_lower rr_ci_upper rr_significance odds_ratio\n",
       "1 round1 1.2857        0.5722       2.8891     NA              1.5714    \n",
       "2 round2 2.6765        0.6628      10.8073     NA              3.8500    \n",
       "3 round3 1.0476        0.5728       1.9160     NA              1.1224    \n",
       "4 round4 0.8889        0.4742       1.6662     NA              0.7619    \n",
       "5 round5 1.1624        0.6247       2.1628     NA              1.4222    \n",
       "  or_ci_lower or_ci_upper or_significance\n",
       "1 0.3592       6.8754     NA             \n",
       "2 0.6430      23.0515     NA             \n",
       "3 0.2534       4.9720     NA             \n",
       "4 0.1791       3.2408     NA             \n",
       "5 0.3276       6.1742     NA             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Relative risk and odds ratio\n",
    "\n",
    "    # Two-tailed z-score\n",
    "p <- 0.05\n",
    "z <- qnorm(1 - p / 2)\n",
    "\n",
    "significance_levels <- list(\n",
    "    \"10pc\" = \"*\",\n",
    "    \"5pc\" = \"**\",\n",
    "    \"1pc\" = \"***\"\n",
    ")\n",
    "\n",
    "    # Construct a data frame\n",
    "ab_results <- tibble(\n",
    "    round = character(),\n",
    "    relative_risk = numeric(),\n",
    "    rr_ci_lower = numeric(),\n",
    "    rr_ci_upper = numeric(),\n",
    "    rr_significance = character(),\n",
    "    odds_ratio = numeric(),\n",
    "    or_ci_lower = numeric(),\n",
    "    or_ci_upper = numeric(),\n",
    "    or_significance = character()\n",
    ")\n",
    "\n",
    "    # Compute the stats\n",
    "for (i in seq_along(df_list)) {\n",
    "    df_name <- names(df_list)[i]\n",
    "    df_i <- df_list[[i]][,2:3]\n",
    "    \n",
    "    # Relative risk\n",
    "    rho_hat <- (df_i[[1,1]] / sum(df_i[1,])) / (df_i[[2,1]] / sum(df_i[2,]))\n",
    "    rr <- round(rho_hat, 4)\n",
    "    # RR confidence interval\n",
    "    rr_se <- sqrt((1 / df_i[[1,1]]) - (1 / sum(df_i[1,])) + (1 / df_i[[2,1]]) - (1 / sum(df_i[2,])))\n",
    "    rr_ci <- c(\n",
    "        round(exp(log(rho_hat) - z * rr_se), 4),\n",
    "        round(exp(log(rho_hat) + z * rr_se), 4)\n",
    "    )\n",
    "    # RR significance\n",
    "    rr_s <- ifelse((rr_ci[1] > 1) | (rr_ci[2] < 1), significance_levels[[paste0(p * 100, \"pc\")]], NA_character_)\n",
    "    \n",
    "    # Odds ratio\n",
    "    theta_hat <- (df_i[[1,1]] * df_i[[2,2]]) / (df_i[[2,1]] * df_i[[1,2]])\n",
    "    or <- round(theta_hat, 4)\n",
    "    # OR confidence interval\n",
    "    or_se <- sqrt(sum(sapply(as.vector(df_i), function(x) (1 / x))))\n",
    "    or_ci <- c(\n",
    "        round(exp(log(theta_hat) - z * or_se), 4),\n",
    "        round(exp(log(theta_hat) + z * or_se), 4)\n",
    "    )\n",
    "    # OR significance\n",
    "    or_s <- ifelse((or_ci[1] > 1) | (or_ci[2] < 1), significance_levels[[paste0(p * 100, \"pc\")]], NA_character_)\n",
    "                             \n",
    "    # Add to results\n",
    "    ab_results <- ab_results |> \n",
    "        add_row(\n",
    "            round = df_name, \n",
    "            relative_risk = rr, \n",
    "            rr_ci_lower = rr_ci[1],\n",
    "            rr_ci_upper = rr_ci[2],\n",
    "            rr_significance = rr_s,\n",
    "            odds_ratio = or, \n",
    "            or_ci_lower = or_ci[1],\n",
    "            or_ci_upper = or_ci[2],\n",
    "            or_significance = or_s\n",
    "        )\n",
    "}\n",
    "\n",
    "ab_results |> head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307c0c4-8087-4f66-80d8-19da2f91bb67",
   "metadata": {},
   "source": [
    "Discuss the findings here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07636f2-7802-4f31-a6e4-80d505feb97b",
   "metadata": {},
   "source": [
    "### Estimating equations model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd843ec-0aec-45f3-bfd2-7bc7584ed093",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>participant_id</th><th scope=col>round</th><th scope=col>sample</th><th scope=col>prediction</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Victor  </td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>Victor  </td><td>2</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>Victor  </td><td>3</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>Victor  </td><td>4</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>Victor  </td><td>5</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>Patricia</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 4\n",
       "\\begin{tabular}{llll}\n",
       " participant\\_id & round & sample & prediction\\\\\n",
       " <fct> & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Victor   & 1 & 0 & 0\\\\\n",
       "\t Victor   & 2 & 1 & 0\\\\\n",
       "\t Victor   & 3 & 0 & 1\\\\\n",
       "\t Victor   & 4 & 0 & 1\\\\\n",
       "\t Victor   & 5 & 0 & 0\\\\\n",
       "\t Patricia & 1 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 4\n",
       "\n",
       "| participant_id &lt;fct&gt; | round &lt;fct&gt; | sample &lt;dbl&gt; | prediction &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| Victor   | 1 | 0 | 0 |\n",
       "| Victor   | 2 | 1 | 0 |\n",
       "| Victor   | 3 | 0 | 1 |\n",
       "| Victor   | 4 | 0 | 1 |\n",
       "| Victor   | 5 | 0 | 0 |\n",
       "| Patricia | 1 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  participant_id round sample prediction\n",
       "1 Victor         1     0      0         \n",
       "2 Victor         2     1      0         \n",
       "3 Victor         3     0      1         \n",
       "4 Victor         4     0      1         \n",
       "5 Victor         5     0      0         \n",
       "6 Patricia       1     1      1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimating equations\n",
    "\n",
    "gee_df <- data_df |>\n",
    "    select(-ends_with(\"confidence\")) |>\n",
    "    pivot_longer(\n",
    "        cols = -participant_id,\n",
    "        names_to = c(\"round\", \".value\"),\n",
    "        names_pattern = \"^round(\\\\d+)_(.+)$\"\n",
    "    ) |>\n",
    "    mutate(\n",
    "        participant_id = as.factor(participant_id),\n",
    "        round = as.factor(round)\n",
    "    )\n",
    "\n",
    "gee_df |> head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5836d24-a064-4c2e-81a7-6de5474f6c9e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'geepack' was built under R version 4.5.2\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "geeglm(formula = prediction ~ sample, family = binomial, data = gee_df, \n",
      "    id = participant_id, corstr = \"exchangeable\")\n",
      "\n",
      " Coefficients:\n",
      "            Estimate Std.err  Wald Pr(>|W|)\n",
      "(Intercept)  -0.1362  0.2203 0.382    0.536\n",
      "sample        0.3262  0.3312 0.970    0.325\n",
      "\n",
      "Correlation structure = exchangeable \n",
      "Estimated Scale Parameters:\n",
      "\n",
      "            Estimate Std.err\n",
      "(Intercept)        1 0.01507\n",
      "  Link = identity \n",
      "\n",
      "Estimated Correlation Parameters:\n",
      "      Estimate Std.err\n",
      "alpha  -0.1078 0.04458\n",
      "Number of clusters:   30  Maximum cluster size: 5 \n"
     ]
    }
   ],
   "source": [
    "library(geepack)\n",
    "\n",
    "gee_model <- geeglm(\n",
    "    prediction ~ sample,\n",
    "    id = participant_id, \n",
    "    family = binomial, \n",
    "    corstr = \"exchangeable\", \n",
    "    data = gee_df\n",
    ")\n",
    "\n",
    "# GEE results\n",
    "gee_results <- summary(gee_model)\n",
    "gee_results |> print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c928af86-8faa-4363-a9d3-10bb967fcbba",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Estimates (betas)\n",
    "gee_estimates <- gee_results$geese$mean$estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd71633-1adc-440e-8117-26ef1ee60037",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline probability (s = 0)\n",
    "beta_0 <- gee_estimates[[1]]\n",
    "pi_0 <- 1 / (1 + exp(-beta_0)) # Or plogis(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a73e2e92-5b24-476b-8d26-75a4749236f6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Probability (s = 1)\n",
    "beta_1 <- gee_estimates[[2]]\n",
    "pi_1 <- 1 / (1 + exp(-(beta_0 + beta_1))) # Or plogis(beta_0 + beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "617a0416-4b77-45ad-ac18-89476297eb37",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Population-averaged risk ratio\n",
    "rr_hat <- pi_1 / pi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391dd321-05e7-4979-966e-fa9a7526daa4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# RR CIs\n",
    "Vb <- vcov(gee_model) # geepack vcov\n",
    "g  <- c(pi_0 - pi_1, 1 - pi_1) # Gradient at fitted values\n",
    "\n",
    "gee_rr_ses <- sqrt(as.numeric(t(g) %*% Vb %*% g))\n",
    "\n",
    "gee_rr_cis <- c(\n",
    "  exp(log(rr_hat) - z * gee_rr_ses),\n",
    "  exp(log(rr_hat) + z * gee_rr_ses)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e77f0790-1157-4539-b82a-c0aa77fafc89",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Population-averaged odds ratio\n",
    "or_hat <- exp(beta_1)\n",
    "\n",
    "isTRUE(all.equal(\n",
    "  or_hat,\n",
    "  (pi_1/(1 - pi_1)) / (pi_0/(1 - pi_0)),\n",
    "  tolerance = 1e-8\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3880f27a-39fd-4a16-b7f5-1f1e83aa5490",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# OR CIs\n",
    "gee_or_se <- gee_results$geese$mean$san.se[[2]]\n",
    "\n",
    "gee_or_cis <- c(\n",
    "    exp(log(or_hat) - (z * gee_or_se)),\n",
    "    exp(log(or_hat) + (z * gee_or_se))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74bbfc45-4d67-456d-a66f-cc8b74140dbd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Working correlation matrix\n",
    "gee_wcm <- gee_results$corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896b7e88-e69f-4822-b865-1602637773a0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# WCM CIs\n",
    "gee_wcm_cis <- c(\n",
    "    gee_wcm$Estimate - (z * gee_wcm$Std.err),\n",
    "    gee_wcm$Estimate + (z * gee_wcm$Std.err)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4645977-4bbc-4793-8962-9b064c4bb2b8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 11 of type chr</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>metric</th><td>beta_0 </td><td>pi_0   </td><td>beta_1 </td><td>pi_1   </td><td>risk_ratio</td><td>rr_ci_lo</td><td>rr_ci_hi</td><td>odds_ratio</td><td>or_ci_lo</td><td>or_ci_hi</td><td>wcm_alpha</td></tr>\n",
       "\t<tr><th scope=row>value</th><td>-0.1362</td><td> 0.4660</td><td> 0.3262</td><td> 0.5473</td><td> 1.1750   </td><td> 0.8500 </td><td> 1.6230 </td><td> 1.3860   </td><td> 0.7240 </td><td> 2.6520 </td><td>-0.1078  </td></tr>\n",
       "\t<tr><th scope=row>significance</th><td>NA     </td><td>NA     </td><td>NA     </td><td>NA     </td><td>-         </td><td>NA      </td><td>NA      </td><td>-         </td><td>NA      </td><td>NA      </td><td>-        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 11 of type chr\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "\tmetric & beta\\_0  & pi\\_0    & beta\\_1  & pi\\_1    & risk\\_ratio & rr\\_ci\\_lo & rr\\_ci\\_hi & odds\\_ratio & or\\_ci\\_lo & or\\_ci\\_hi & wcm\\_alpha\\\\\n",
       "\tvalue & -0.1362 &  0.4660 &  0.3262 &  0.5473 &  1.1750    &  0.8500  &  1.6230  &  1.3860    &  0.7240  &  2.6520  & -0.1078  \\\\\n",
       "\tsignificance & NA      & NA      & NA      & NA      & -          & NA       & NA       & -          & NA       & NA       & -        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 11 of type chr\n",
       "\n",
       "| metric | beta_0  | pi_0    | beta_1  | pi_1    | risk_ratio | rr_ci_lo | rr_ci_hi | odds_ratio | or_ci_lo | or_ci_hi | wcm_alpha |\n",
       "| value | -0.1362 |  0.4660 |  0.3262 |  0.5473 |  1.1750    |  0.8500  |  1.6230  |  1.3860    |  0.7240  |  2.6520  | -0.1078   |\n",
       "| significance | NA      | NA      | NA      | NA      | -          | NA       | NA       | -          | NA       | NA       | -         |\n",
       "\n"
      ],
      "text/plain": [
       "             [,1]    [,2]    [,3]    [,4]    [,5]       [,6]     [,7]    \n",
       "metric       beta_0  pi_0    beta_1  pi_1    risk_ratio rr_ci_lo rr_ci_hi\n",
       "value        -0.1362  0.4660  0.3262  0.5473  1.1750     0.8500   1.6230 \n",
       "significance NA      NA      NA      NA      -          NA       NA      \n",
       "             [,8]       [,9]     [,10]    [,11]    \n",
       "metric       odds_ratio or_ci_lo or_ci_hi wcm_alpha\n",
       "value         1.3860     0.7240   2.6520  -0.1078  \n",
       "significance -          NA       NA       -        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct a df with GEE results\n",
    "gee_res_df <- tribble(\n",
    "    ~metric, ~value, ~significance,\n",
    "    \"beta_0\", beta_0, NA,\n",
    "    \"pi_0\", pi_0, NA,\n",
    "    \"beta_1\", beta_1, NA,\n",
    "    \"pi_1\", pi_1, NA,\n",
    "    \"risk_ratio\", round(rr_hat, 3), ifelse((gee_rr_cis[[1]] > 1) | (gee_rr_cis[[2]] < 1), \"**\", \"-\"),\n",
    "    \"rr_ci_lo\", round(gee_rr_cis[[1]], 3), NA,\n",
    "    \"rr_ci_hi\", round(gee_rr_cis[[2]], 3), NA,\n",
    "    \"odds_ratio\", round(or_hat, 3), ifelse((gee_or_cis[[1]] > 1) | (gee_or_cis[[2]] < 1), \"**\", \"-\"),\n",
    "    \"or_ci_lo\", round(gee_or_cis[[1]], 3), NA,\n",
    "    \"or_ci_hi\", round(gee_or_cis[[2]], 3), NA,\n",
    "    \"wcm_alpha\", gee_wcm$Estimate, ifelse((gee_wcm_cis[[1]] / gee_wcm_cis[[2]]) < p, \"**\", \"-\")\n",
    "    # \"wcm_ci_lo\", round(gee_wcm_cis[[1]], 3), NA,\n",
    "    # \"wcm_ci_hi\", round(gee_wcm_cis[[2]], 3), NA\n",
    ")\n",
    "\n",
    "gee_res_df |> t() |> head(n=nrow(gee_res_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a72db6-11d1-4309-8bcc-b330dbc70523",
   "metadata": {},
   "source": [
    "Discuss the findings here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d5a9d-4f37-4d79-862d-18bdd03574a7",
   "metadata": {},
   "source": [
    "### Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42a8bb39-8c91-4d4d-a074-ade8d02bf4f7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 10 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>participant_id</th><th scope=col>brier_score</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Anna    </td><td>0.1647</td></tr>\n",
       "\t<tr><td>Deborah </td><td>0.1811</td></tr>\n",
       "\t<tr><td>Mabel   </td><td>0.2031</td></tr>\n",
       "\t<tr><td>William </td><td>0.2236</td></tr>\n",
       "\t<tr><td>Stanley </td><td>0.2305</td></tr>\n",
       "\t<tr><td>James   </td><td>0.2486</td></tr>\n",
       "\t<tr><td>Patricia</td><td>0.2520</td></tr>\n",
       "\t<tr><td>Charlene</td><td>0.2782</td></tr>\n",
       "\t<tr><td>Lily    </td><td>0.2899</td></tr>\n",
       "\t<tr><td>David   </td><td>0.3008</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 10 × 2\n",
       "\\begin{tabular}{ll}\n",
       " participant\\_id & brier\\_score\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Anna     & 0.1647\\\\\n",
       "\t Deborah  & 0.1811\\\\\n",
       "\t Mabel    & 0.2031\\\\\n",
       "\t William  & 0.2236\\\\\n",
       "\t Stanley  & 0.2305\\\\\n",
       "\t James    & 0.2486\\\\\n",
       "\t Patricia & 0.2520\\\\\n",
       "\t Charlene & 0.2782\\\\\n",
       "\t Lily     & 0.2899\\\\\n",
       "\t David    & 0.3008\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 10 × 2\n",
       "\n",
       "| participant_id &lt;chr&gt; | brier_score &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| Anna     | 0.1647 |\n",
       "| Deborah  | 0.1811 |\n",
       "| Mabel    | 0.2031 |\n",
       "| William  | 0.2236 |\n",
       "| Stanley  | 0.2305 |\n",
       "| James    | 0.2486 |\n",
       "| Patricia | 0.2520 |\n",
       "| Charlene | 0.2782 |\n",
       "| Lily     | 0.2899 |\n",
       "| David    | 0.3008 |\n",
       "\n"
      ],
      "text/plain": [
       "   participant_id brier_score\n",
       "1  Anna           0.1647     \n",
       "2  Deborah        0.1811     \n",
       "3  Mabel          0.2031     \n",
       "4  William        0.2236     \n",
       "5  Stanley        0.2305     \n",
       "6  James          0.2486     \n",
       "7  Patricia       0.2520     \n",
       "8  Charlene       0.2782     \n",
       "9  Lily           0.2899     \n",
       "10 David          0.3008     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Brier score\n",
    "bs_results <- data_df |>\n",
    "    mutate(\n",
    "        across(\n",
    "            .cols = ends_with(\"sample\"),\n",
    "            .fns = ~ (as.integer(.x == data_df[[str_replace(cur_column(), \"sample$\", \"prediction\")]]) - data_df[[str_replace(cur_column(), \"sample$\", \"confidence\")]])^2,\n",
    "            .names = \"{str_replace(.col, 'sample$', 'brier')}\"\n",
    "        )\n",
    "    ) |>\n",
    "    rowwise() |>\n",
    "    mutate(\n",
    "        brier_score = mean(c_across(ends_with(\"brier\")), na.rm = TRUE)\n",
    "    ) |>\n",
    "    ungroup() |>\n",
    "    select(participant_id, brier_score) |>\n",
    "    arrange(brier_score)\n",
    "\n",
    "head(bs_results, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd1208-a169-4a14-ad0d-69d88606ba3f",
   "metadata": {},
   "source": [
    "Discuss the findings here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919e205-33f5-4a65-aa85-57226082e6ff",
   "metadata": {},
   "source": [
    "### Bayesian estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa24926-a8e5-40bf-a95b-4c2d120d65fb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is cmdstanr version 0.9.0\n",
      "\n",
      "- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n",
      "\n",
      "- CmdStan path: C:/Users/rosec/.cmdstan/cmdstan-2.37.0\n",
      "\n",
      "- CmdStan version: 2.37.0\n",
      "\n",
      "This is posterior version 1.6.1\n",
      "\n",
      "\n",
      "Attaching package: 'posterior'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    mad, sd, var\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    %in%, match\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Summary and diagnostics for  round1 : \n",
      "\u001b[90m# A tibble: 5 × 10\u001b[39m\n",
      "  variable      mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m lp__       -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m8\u001b[39m   -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m5\u001b[39m   1.03  0.724 -\u001b[31m24\u001b[39m\u001b[31m.\u001b[39m\u001b[31m8\u001b[39m   -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m8\u001b[39m   1.00     \u001b[4m3\u001b[24m818.    \u001b[4m5\u001b[24m370.\n",
      "\u001b[90m2\u001b[39m p[1]         0.500   0.501 0.133 0.139   0.279   0.721 1.00     \u001b[4m7\u001b[24m078.    \u001b[4m5\u001b[24m776.\n",
      "\u001b[90m3\u001b[39m p[2]         0.394   0.392 0.108 0.112   0.221   0.580 1.000    \u001b[4m8\u001b[24m431.    \u001b[4m5\u001b[24m929.\n",
      "\u001b[90m4\u001b[39m risk_ratio   1.38    1.27  0.608 0.485   0.641   2.49  1.000    \u001b[4m7\u001b[24m547.    \u001b[4m6\u001b[24m248.\n",
      "\u001b[90m5\u001b[39m odds_ratio   2.08    1.56  1.82  1.06    0.463   5.23  1.00     \u001b[4m7\u001b[24m427.    \u001b[4m6\u001b[24m298.\n",
      "\n",
      "#### Summary and diagnostics for  round2 : \n",
      "\u001b[90m# A tibble: 5 × 10\u001b[39m\n",
      "  variable      mean  median     sd    mad       q5     q95  rhat ess_bulk\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m lp__       -\u001b[31m19\u001b[39m\u001b[31m.\u001b[39m\u001b[31m8\u001b[39m   -\u001b[31m19\u001b[39m\u001b[31m.\u001b[39m\u001b[31m5\u001b[39m   1.02   0.734  -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m    -\u001b[31m18\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m    1.00    \u001b[4m4\u001b[24m652.\n",
      "\u001b[90m2\u001b[39m p[1]         0.414   0.410 0.113  0.116    0.234    0.607  1.00    \u001b[4m6\u001b[24m575.\n",
      "\u001b[90m3\u001b[39m p[2]         0.179   0.164 0.098\u001b[4m5\u001b[24m 0.096\u001b[4m9\u001b[24m   0.046\u001b[4m0\u001b[24m   0.364  1.00    \u001b[4m7\u001b[24m522.\n",
      "\u001b[90m4\u001b[39m risk_ratio   3.52    2.51  4.12   1.58     0.946    9.08   1.00    \u001b[4m7\u001b[24m490.\n",
      "\u001b[90m5\u001b[39m odds_ratio   5.85    3.62  8.53   2.92     0.921   17.1    1.00    \u001b[4m7\u001b[24m465.\n",
      "\u001b[90m# ℹ 1 more variable: ess_tail <dbl>\u001b[39m\n",
      "\n",
      "#### Summary and diagnostics for  round3 : \n",
      "\u001b[90m# A tibble: 5 × 10\u001b[39m\n",
      "  variable      mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m lp__       -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m   -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m3\u001b[39m   1.06  0.731 -\u001b[31m24\u001b[39m\u001b[31m.\u001b[39m\u001b[31m7\u001b[39m   -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m7\u001b[39m    1.00    \u001b[4m4\u001b[24m037.    \u001b[4m5\u001b[24m729.\n",
      "\u001b[90m2\u001b[39m p[1]         0.605   0.609 0.109 0.115   0.420   0.774  1.00    \u001b[4m7\u001b[24m740.    \u001b[4m6\u001b[24m272.\n",
      "\u001b[90m3\u001b[39m p[2]         0.579   0.583 0.134 0.140   0.352   0.792  1.00    \u001b[4m7\u001b[24m620.    \u001b[4m5\u001b[24m720.\n",
      "\u001b[90m4\u001b[39m risk_ratio   1.12    1.04  0.391 0.306   0.646   1.82   1.00    \u001b[4m7\u001b[24m788.    \u001b[4m6\u001b[24m353.\n",
      "\u001b[90m5\u001b[39m odds_ratio   1.48    1.11  1.33  0.776   0.309   3.81   1.00    \u001b[4m7\u001b[24m629.    \u001b[4m5\u001b[24m623.\n",
      "\n",
      "#### Summary and diagnostics for  round4 : \n",
      "\u001b[90m# A tibble: 5 × 10\u001b[39m\n",
      "  variable      mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m lp__       -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m   -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m   1.02  0.720 -\u001b[31m24\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m   -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m    1.00    \u001b[4m4\u001b[24m063.    \u001b[4m5\u001b[24m074.\n",
      "\u001b[90m2\u001b[39m p[1]         0.530   0.531 0.121 0.128   0.331   0.726  1.00    \u001b[4m8\u001b[24m213.    \u001b[4m6\u001b[24m749.\n",
      "\u001b[90m3\u001b[39m p[2]         0.593   0.597 0.118 0.123   0.394   0.779  1.00    \u001b[4m7\u001b[24m360.    \u001b[4m5\u001b[24m433.\n",
      "\u001b[90m4\u001b[39m risk_ratio   0.936   0.893 0.311 0.272   0.516   1.50   1.00    \u001b[4m7\u001b[24m826.    \u001b[4m6\u001b[24m176.\n",
      "\u001b[90m5\u001b[39m odds_ratio   0.996   0.765 0.847 0.518   0.228   2.50   1.00    \u001b[4m7\u001b[24m746.    \u001b[4m6\u001b[24m394.\n",
      "\n",
      "#### Summary and diagnostics for  round5 : \n",
      "\u001b[90m# A tibble: 5 × 10\u001b[39m\n",
      "  variable      mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m lp__       -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m   -\u001b[31m22\u001b[39m\u001b[31m.\u001b[39m\u001b[31m5\u001b[39m   1.05  0.728 -\u001b[31m25\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m   -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m9\u001b[39m    1.00    \u001b[4m4\u001b[24m541.    \u001b[4m5\u001b[24m701.\n",
      "\u001b[90m2\u001b[39m p[1]         0.605   0.611 0.126 0.131   0.386   0.807  1.00    \u001b[4m9\u001b[24m103.    \u001b[4m6\u001b[24m418.\n",
      "\u001b[90m3\u001b[39m p[2]         0.527   0.527 0.115 0.122   0.338   0.713  1.00    \u001b[4m7\u001b[24m995.    \u001b[4m6\u001b[24m296.\n",
      "\u001b[90m4\u001b[39m risk_ratio   1.21    1.15  0.400 0.350   0.681   1.93   1.00    \u001b[4m8\u001b[24m425.    \u001b[4m6\u001b[24m480.\n",
      "\u001b[90m5\u001b[39m odds_ratio   1.86    1.41  1.61  0.975   0.428   4.71   1.00    \u001b[4m8\u001b[24m618.    \u001b[4m6\u001b[24m802.\n",
      "\n",
      "#### Risk and odds ratios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>round</th><th scope=col>p_1</th><th scope=col>p_2</th><th scope=col>risk_ratio</th><th scope=col>rr_lower</th><th scope=col>rr_upper</th><th scope=col>rr_significance</th><th scope=col>odds_ratio</th><th scope=col>or_lower</th><th scope=col>or_upper</th><th scope=col>or_significance</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>round1</td><td>0.5006</td><td>0.3916</td><td>1.2707</td><td>0.5442</td><td> 2.870</td><td>NA</td><td>1.5578</td><td>0.3664</td><td> 6.843</td><td>NA</td></tr>\n",
       "\t<tr><td>round2</td><td>0.4103</td><td>0.1642</td><td>2.5096</td><td>0.8052</td><td>12.385</td><td>NA</td><td>3.6176</td><td>0.7270</td><td>24.215</td><td>NA</td></tr>\n",
       "\t<tr><td>round3</td><td>0.6088</td><td>0.5834</td><td>1.0436</td><td>0.5750</td><td> 2.036</td><td>NA</td><td>1.1145</td><td>0.2349</td><td> 4.809</td><td>NA</td></tr>\n",
       "\t<tr><td>round4</td><td>0.5311</td><td>0.5974</td><td>0.8931</td><td>0.4618</td><td> 1.664</td><td>NA</td><td>0.7651</td><td>0.1779</td><td> 3.123</td><td>NA</td></tr>\n",
       "\t<tr><td>round5</td><td>0.6114</td><td>0.5266</td><td>1.1526</td><td>0.6051</td><td> 2.160</td><td>NA</td><td>1.4089</td><td>0.3355</td><td> 6.148</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 11\n",
       "\\begin{tabular}{lllllllllll}\n",
       " round & p\\_1 & p\\_2 & risk\\_ratio & rr\\_lower & rr\\_upper & rr\\_significance & odds\\_ratio & or\\_lower & or\\_upper & or\\_significance\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t round1 & 0.5006 & 0.3916 & 1.2707 & 0.5442 &  2.870 & NA & 1.5578 & 0.3664 &  6.843 & NA\\\\\n",
       "\t round2 & 0.4103 & 0.1642 & 2.5096 & 0.8052 & 12.385 & NA & 3.6176 & 0.7270 & 24.215 & NA\\\\\n",
       "\t round3 & 0.6088 & 0.5834 & 1.0436 & 0.5750 &  2.036 & NA & 1.1145 & 0.2349 &  4.809 & NA\\\\\n",
       "\t round4 & 0.5311 & 0.5974 & 0.8931 & 0.4618 &  1.664 & NA & 0.7651 & 0.1779 &  3.123 & NA\\\\\n",
       "\t round5 & 0.6114 & 0.5266 & 1.1526 & 0.6051 &  2.160 & NA & 1.4089 & 0.3355 &  6.148 & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 11\n",
       "\n",
       "| round &lt;chr&gt; | p_1 &lt;dbl&gt; | p_2 &lt;dbl&gt; | risk_ratio &lt;dbl&gt; | rr_lower &lt;dbl&gt; | rr_upper &lt;dbl&gt; | rr_significance &lt;chr&gt; | odds_ratio &lt;dbl&gt; | or_lower &lt;dbl&gt; | or_upper &lt;dbl&gt; | or_significance &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| round1 | 0.5006 | 0.3916 | 1.2707 | 0.5442 |  2.870 | NA | 1.5578 | 0.3664 |  6.843 | NA |\n",
       "| round2 | 0.4103 | 0.1642 | 2.5096 | 0.8052 | 12.385 | NA | 3.6176 | 0.7270 | 24.215 | NA |\n",
       "| round3 | 0.6088 | 0.5834 | 1.0436 | 0.5750 |  2.036 | NA | 1.1145 | 0.2349 |  4.809 | NA |\n",
       "| round4 | 0.5311 | 0.5974 | 0.8931 | 0.4618 |  1.664 | NA | 0.7651 | 0.1779 |  3.123 | NA |\n",
       "| round5 | 0.6114 | 0.5266 | 1.1526 | 0.6051 |  2.160 | NA | 1.4089 | 0.3355 |  6.148 | NA |\n",
       "\n"
      ],
      "text/plain": [
       "  round  p_1    p_2    risk_ratio rr_lower rr_upper rr_significance odds_ratio\n",
       "1 round1 0.5006 0.3916 1.2707     0.5442    2.870   NA              1.5578    \n",
       "2 round2 0.4103 0.1642 2.5096     0.8052   12.385   NA              3.6176    \n",
       "3 round3 0.6088 0.5834 1.0436     0.5750    2.036   NA              1.1145    \n",
       "4 round4 0.5311 0.5974 0.8931     0.4618    1.664   NA              0.7651    \n",
       "5 round5 0.6114 0.5266 1.1526     0.6051    2.160   NA              1.4089    \n",
       "  or_lower or_upper or_significance\n",
       "1 0.3664    6.843   NA             \n",
       "2 0.7270   24.215   NA             \n",
       "3 0.2349    4.809   NA             \n",
       "4 0.1779    3.123   NA             \n",
       "5 0.3355    6.148   NA             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bayesian estimates\n",
    "    # Libraries\n",
    "library(cmdstanr)\n",
    "library(posterior)\n",
    "\n",
    "    # Stan script\n",
    "stan_script <- \"\n",
    "data {\n",
    "    int<lower=1> K; // {treatment, control}\n",
    "    array[K] int<lower=0> n; // Trials per group\n",
    "    array[K] int<lower=0> y; // Successes per group\n",
    "}\n",
    "parameters {\n",
    "    vector<lower=0, upper=1>[K] p;\n",
    "}\n",
    "model {\n",
    "    // Jeffreys prior\n",
    "    p ~ beta(0.5, 0.5);\n",
    "\n",
    "    // Binomial likelihood\n",
    "    y ~ binomial(n, p);\n",
    "}\n",
    "generated quantities {\n",
    "    real risk_ratio = p[1] / p[2];\n",
    "    real odds_ratio = (p[1] / (1 - p[1])) / (p[2] / (1 - p[2]));\n",
    "}\n",
    "\"\n",
    "\n",
    "    # Write the Stan model into a file\n",
    "stan_file <- write_stan_file(stan_script)\n",
    "    # Compile the model\n",
    "mod <- cmdstan_model(stan_file)\n",
    "\n",
    "    # df\n",
    "bayes_df <- tibble(\n",
    "    round = character(),\n",
    "    p_1 = numeric(),\n",
    "    p_2 = numeric(),\n",
    "    risk_ratio = numeric(),\n",
    "    rr_lower = numeric(),\n",
    "    rr_upper = numeric(),\n",
    "    rr_significance = character(),\n",
    "    odds_ratio = numeric(),\n",
    "    or_lower = numeric(),\n",
    "    or_upper = numeric(),\n",
    "    or_significance = character()\n",
    ")\n",
    "\n",
    "for (i in seq_along(df_list)) {\n",
    "    # Contingency table\n",
    "    name_i <- names(df_list)[i]\n",
    "    contingency_table_i <- df_list[[name_i]][,2:3]\n",
    "    ct <- as.matrix(contingency_table_i)\n",
    "  \n",
    "    # Stan data\n",
    "    stan_data <- list(\n",
    "        K = 2, # {treatment, control}\n",
    "        n = as.integer(c(sum(ct[1, ]), sum(ct[2, ]))), # Trials per group\n",
    "        y = as.integer(c(ct[1, 1], ct[2, 1])) # Successes per group\n",
    "    )\n",
    "  \n",
    "    # Sample\n",
    "    fit <- mod$sample(\n",
    "        data = stan_data,\n",
    "        chains = 6, \n",
    "        parallel_chains = 6,\n",
    "        iter_warmup = 4e2L, # 4e3L\n",
    "        iter_sampling = 16e2L, # 16e3L\n",
    "        seed = 42,\n",
    "        refresh = 0, # Suppresses progress updates\n",
    "        show_messages = FALSE # Suppresses Stan messages\n",
    "    )\n",
    "\n",
    "    draws <- fit$draws(c(\"p\", \"risk_ratio\", \"odds_ratio\"))\n",
    "\n",
    "    # Sampling diagnostics\n",
    "    fit_summary <- fit$summary()\n",
    "    # fit_diagnostics <- fit$cmdstan_diagnose() # NUTS diagnostics\n",
    "    # fit_raw <- fit$save_output_files() # Raw chain files\n",
    "\n",
    "    cat(\"\\n#### Summary and diagnostics for \", name_i, \": \\n\")\n",
    "    print(fit_summary)\n",
    "    # print(fit_diagnostics)\n",
    "\n",
    "    # Posterior summaries\n",
    "    draws_mat <- as_draws_matrix(fit$draws(c(\"p[1]\",\"p[2]\",\"risk_ratio\",\"odds_ratio\")))\n",
    "    rr_q <- quantile(draws_mat[, \"risk_ratio\"], probs = c(0.025, 0.5, 0.975))\n",
    "    or_q <- quantile(draws_mat[, \"odds_ratio\"], probs = c(0.025, 0.5, 0.975))\n",
    "  \n",
    "    results_i <- tibble(\n",
    "        round = name_i,\n",
    "        p_1 = median(draws_mat[, \"p[1]\"]),\n",
    "        p_2 = median(draws_mat[, \"p[2]\"]),\n",
    "        risk_ratio = median(draws_mat[, \"risk_ratio\"]),\n",
    "        rr_lower = rr_q[1], rr_upper = rr_q[3],\n",
    "        rr_significance = ifelse((rr_q[[1]] > 1) | (rr_q[[3]] < 1), \"**\", NA_character_),\n",
    "        odds_ratio = median(draws_mat[, \"odds_ratio\"]),\n",
    "        or_lower = or_q[1], or_upper = or_q[3],\n",
    "        or_significance = ifelse((or_q[[1]] > 1) | (or_q[[3]] < 1), \"**\", NA_character_)\n",
    "    )\n",
    "  \n",
    "    bayes_df <- bayes_df |>\n",
    "        add_row(results_i)\n",
    "}\n",
    "\n",
    "cat(\"\\n#### Risk and odds ratios:\\n\")\n",
    "bayes_df |> head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd65dd5-ccbf-4665-beec-b23cb66efa32",
   "metadata": {},
   "source": [
    "Discuss the findings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6f3e9-a933-4fa3-a043-7e5f91a67d40",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
